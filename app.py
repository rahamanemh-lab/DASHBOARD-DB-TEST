"""
Dashboard Commercial - Application principale
Version 2.0 avec configuration centralis√©e et am√©lirations
"""

import streamlit as st
import pandas as pd
import os
import sys
import logging
from datetime import datetime
from pathlib import Path
import calendar
import plotly.graph_objects as go
import numpy as np
from contextlib import contextmanager
import json
import requests
from typing import Optional, Dict, Any

# =============================================================================
# SECTION CRYPTO - TEST CONNEXION LIGHTSAIL
# =============================================================================
import os
import pandas as pd
import pymysql
import streamlit as st

st.set_page_config(page_title="Crypto Lightsail (SSL)", layout="wide")
st.title("üîê Connexion SSL √† Lightsail MySQL")

def get_db_conf():
    # 1) Streamlit Cloud secrets
    if "database" in st.secrets:
        cfg = st.secrets["database"]
        return {
            "host": cfg["host"],
            "user": cfg["user"],
            "password": cfg["password"],
            "database": cfg["dbname"],
            "port": int(cfg.get("port", 3306)),
            "ca": cfg.get("ssl_ca", None)  # chemin optionnel du CA si fourni
        }
    # 2) Fallback: env vars (local)
    return {
        "host": os.getenv("DB_HOST"),
        "user": os.getenv("DB_USER"),
        "password": os.getenv("DB_PASSWORD"),
        "database": os.getenv("DB_NAME", "crypto_datalake"),
        "port": int(os.getenv("DB_PORT", "3306")),
        "ca": os.getenv("DB_SSL_CA")  # ex: ./certs/rds-combined-ca-bundle.pem
    }

cfg = get_db_conf()
if not all([cfg["host"], cfg["user"], cfg["password"], cfg["database"]]):
    st.error("Config manquante: host/user/password/database")
    st.stop()

# SSL kwargs: avec CA si dispo, sinon SSL rapide (sans v√©rification)
ssl_kwargs = {"ssl": {"ca": cfg["ca"]}} if cfg.get("ca") else {"ssl": {"ssl": {}}}

# Connexion + ping
try:
    conn = pymysql.connect(
        host=cfg["host"],
        user=cfg["user"],
        password=cfg["password"],
        database=cfg["database"],
        port=cfg["port"],
        charset="utf8mb4",
        connect_timeout=10,
        **ssl_kwargs
    )
    with conn.cursor() as c:
        c.execute("SELECT NOW(), USER(), CURRENT_USER(), VERSION()")
        now, user, cur_user, ver = c.fetchone()
    st.success(f"‚úÖ SSL OK ‚Äî NOW={now} | USER()={user} | CURRENT_USER()={cur_user} | MySQL={ver}")
except Exception as e:
    st.error(f"‚ùå Connexion √©chou√©e : {e}")
    st.stop()


def render_crypto_test_section():
    # Lecture + graphe
    df = pd.read_sql("""
        SELECT ts_utc AS ts, asset, fiat, price
        FROM crypto_prices
        WHERE ts_utc >= NOW() - INTERVAL 1 DAY
        ORDER BY ts_utc DESC
        LIMIT 500
    """, conn)
    conn.close()
    
    if df.empty:
        st.warning("Aucune ligne dans crypto_prices (24h).")
    else:
        st.dataframe(df.head(20), use_container_width=True)
        df["ts"] = pd.to_datetime(df["ts"], errors="coerce")
        df = df.dropna(subset=["ts","price"]).sort_values(["ts","asset"])
        pivot = (
            df.groupby(["ts","asset"], as_index=False)["price"].mean()
              .pivot(index="ts", columns="asset", values="price")
              .sort_index()
        )
        st.subheader("üìà Prix par asset (derni√®res 24h)")
        st.line_chart(pivot)



# =============================================================================

# =============================================================================
def make_epargne_from_crypto(df_crypto: pd.DataFrame) -> pd.DataFrame:
    """
    Map crypto -> sch√©ma √âPARGNE attendu par le dashboard.
    Colonnes produites : 
      - Date de souscription (datetime)
      - Montant (float)
      - Montant du placement (float)  # utile pour 'Retard cumul√©'
      - Conseiller (str)
      - Produit (str)
      - Statut/√âtape (str)
    """
    if df_crypto is None or df_crypto.empty:
        return pd.DataFrame(columns=[
            "Date de souscription","Montant","Montant du placement","Conseiller","Produit","Statut/√âtape"
        ])
    df = df_crypto.copy()
    df["Date de souscription"] = pd.to_datetime(df["ts"], errors="coerce")  # ts vient de ts_utc AS ts
    df["Montant"] = pd.to_numeric(df["price"], errors="coerce")
    df["Montant du placement"] = df["Montant"]  # pour la section 'Retard cumul√©' :contentReference[oaicite:3]{index=3}
    df["Conseiller"] = "Demo (Lightsail)"
    df["Produit"] = df["asset"].astype(str).str.upper()
    df["Statut/√âtape"] = "Valid√©"
    out = df[[
        "Date de souscription","Montant","Montant du placement","Conseiller","Produit","Statut/√âtape"
    ]].dropna(subset=["Date de souscription","Montant"])
    return out


def make_immo_from_crypto(df_crypto: pd.DataFrame) -> pd.DataFrame:
    """
    Map crypto -> sch√©ma IMMOBILIER attendu par le dashboard.
    Colonnes produites :
      - Date de cr√©ation (datetime)
      - Conseiller (str)
      - Statut (str)
      - Montant (float)
      - Type de bien (str)
    """
    if df_crypto is None or df_crypto.empty:
        return pd.DataFrame(columns=[
            "Date de cr√©ation","Conseiller","Statut","Montant","Type de bien"
        ])
    df = df_crypto.copy()
    df["Date de cr√©ation"] = pd.to_datetime(df["ts"], errors="coerce")
    df["Montant"] = pd.to_numeric(df["price"], errors="coerce")
    df["Conseiller"] = "Demo (Lightsail)"
    df["Statut"] = "En cours"
    # on ‚Äúr√©utilise‚Äù asset comme pseudo-type
    df["Type de bien"] = df["asset"].astype(str).str.upper()
    out = df[["Date de cr√©ation","Conseiller","Statut","Montant","Type de bien"]].dropna(subset=["Date de cr√©ation","Montant"])
    return out


# =============================================================================

#S3 CONFIG

# =============================================================================
import boto3
from io import BytesIO
from urllib.parse import urlparse

@st.cache_resource(ttl=300, show_spinner=False)
def _get_s3_client():
    # lit d‚Äôabord dans st.secrets, sinon variables d‚Äôenv
    region = (st.secrets.get("s3", {}) or {}).get("region") or os.getenv("AWS_DEFAULT_REGION", "eu-north-1")
    aws_id = (st.secrets.get("s3", {}) or {}).get("aws_access_key_id") or os.getenv("AWS_ACCESS_KEY_ID")
    aws_sk = (st.secrets.get("s3", {}) or {}).get("aws_secret_access_key") or os.getenv("AWS_SECRET_ACCESS_KEY")
    params = {"region_name": region}
    if aws_id and aws_sk:
        params.update({"aws_access_key_id": aws_id, "aws_secret_access_key": aws_sk})
    return boto3.client("s3", **params)

def _s3_conf():
    # r√©cup√®re bucket + mapping des pr√©fixes
    s3sec = st.secrets.get("s3", {}) or {}
    return {
        "bucket": s3sec.get("bucket") or os.getenv("S3_BUCKET"),
        "region": s3sec.get("region") or os.getenv("AWS_DEFAULT_REGION", "eu-north-1"),
        "prefixes": {
            "epargne": s3sec.get("epargne_prefix") or os.getenv("S3_EPARGNE_PREFIX", "inputs/epargne/"),
            "immo": s3sec.get("immo_prefix") or os.getenv("S3_IMMO_PREFIX", "inputs/immo/"),
            "rdv": s3sec.get("rdv_prefix") or os.getenv("S3_RDV_PREFIX", "inputs/rdv/"),
            "clients": s3sec.get("clients_prefix") or os.getenv("S3_CLIENTS_PREFIX", "inputs/clients/"),
            "entretiens_epargne": s3sec.get("entretiens_epargne_prefix") or os.getenv("S3_ENT_EP_PREFIX", "inputs/entretiens_epargne/"),
            "entretiens_immo": s3sec.get("entretiens_immo_prefix") or os.getenv("S3_ENT_IMMO_PREFIX", "inputs/entretiens_immo/"),
            "paiements_epargne": s3sec.get("paiements_epargne_prefix") or os.getenv("S3_PAY_EP_PREFIX", "inputs/paiements_epargne/"),
            "paiements_immo": s3sec.get("paiements_immo_prefix") or os.getenv("S3_PAY_IMMO_PREFIX", "inputs/paiements_immo/"),
            "analyse_2025": s3sec.get("analyse_2025_prefix") or os.getenv("S3_2025_PREFIX", "inputs/analyse_2025/"),
        },
        "extensions": (s3sec.get("extensions") or "xlsx,csv").split(",")
    }

@st.cache_data(ttl=120, show_spinner=False, hash_funcs={"botocore.client.S3": lambda _: None})
def s3_latest_key(bucket: str, prefix: str, allowed_ext=("xlsx","xls","csv")) -> str | None:
    s3 = _get_s3_client()
    paginator = s3.get_paginator("list_objects_v2")
    latest = None
    latest_ts = None
    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):
        for obj in page.get("Contents", []):
            key = obj["Key"]
            if any(key.lower().endswith("."+ext.lower()) for ext in allowed_ext):
                ts = obj["LastModified"]
                if latest_ts is None or ts > latest_ts:
                    latest, latest_ts = key, ts
    return latest

@st.cache_data(ttl=120, show_spinner=False, hash_funcs={"botocore.client.S3": lambda _: None})
def s3_read_excel_or_csv(bucket: str, key: str) -> pd.DataFrame | None:
    s3 = _get_s3_client()
    obj = s3.get_object(Bucket=bucket, Key=key)
    data = obj["Body"].read()
    if key.lower().endswith((".xlsx",".xls")):
        return pd.read_excel(BytesIO(data))
    elif key.lower().endswith(".csv"):
        # essai auto d'encodage ; ajuste si besoin
        try:
            return pd.read_csv(BytesIO(data))
        except Exception:
            return pd.read_csv(BytesIO(data), encoding="utf-8", sep=";")
    return None

def auto_load_from_s3(kind: str, description: str = "") -> pd.DataFrame | None:
    cfg = _s3_conf()
    bucket = cfg["bucket"]
    if not bucket:
        st.warning("S3 non configur√© (bucket manquant).")
        return None
    prefix = cfg["prefixes"].get(kind)
    if not prefix:
        st.warning(f"Pr√©fixe S3 manquant pour {kind}.")
        return None
    key = s3_latest_key(bucket, prefix, cfg["extensions"])
    if not key:
        st.info(f"Aucun fichier trouv√© sur S3 sous `{prefix}` pour {kind}.")
        return None
    with st.spinner(f"üì• Chargement S3 ({description or kind})‚Ä¶"):
        df = s3_read_excel_or_csv(bucket, key)
    if df is not None:
        st.success(f"‚úÖ Charg√© depuis S3: s3://{bucket}/{key}")
    return df






# =============================================================================

# ‚ö†Ô∏è CECI DOIT √äTRE LA PREMI√àRE COMMANDE STREAMLIT
# st.set_page_config(
#     page_title="Dashboard Souscriptions",
#     page_icon="üìä",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )

# Configuration du path pour les imports
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# Import du syst√®me de configuration
try:
    from utils.config_loader import config, get_config, get_theme_colors, get_chart_config
    CONFIG_LOADED = True
except ImportError:
    logging.warning("Configuration loader non disponible, utilisation des valeurs par d√©faut")
    CONFIG_LOADED = False
    
# Configuration des objectifs
OBJECTIF_MENSUEL_EPARGNE = 1_830_000
OBJECTIF_ANNUEL_EPARGNE = 22_000_000  # 22M‚Ç¨ objectif annuel

# Import des modules d'analyse
from analyses.epargne import analyser_souscriptions_epargne
from analyses.souscription_epargne import analyser_pipe_collecte_epargne
from analyses.epargne_groupe import analyser_groupes_epargne, analyser_performance_conseillers_epargne
from analyses.immo import analyser_suivi_immo
from analyses.immo_status import analyser_statuts_dossiers_immo
from analyses.immo_groupe import analyser_groupes_dossiers_immo
from analyses.entretiens import analyser_entretiens
import analyses.entretiens
from analyses.rdv import analyser_rdv
from analyses.conversion import analyser_conversion
from analyses.parcours_client import analyser_parcours_client
from analyses.paiements import analyser_paiements
from analyses.clients import analyser_clients
from analyses.clients_integration import analyser_clients_integration

# Import des fonctions utilitaires
from utils.data_processing import read_excel_robust, safe_to_datetime



# ================================================================================
# Classe LLM Assistant
# ================================================================================

class LLMAssistant:
    """Assistant LLM intelligent pour l'analyse de donn√©es"""
    
    def __init__(self):
        self.available_models = {
            "openai": {
                "name": "OpenAI GPT-4",
                "endpoint": "https://api.openai.com/v1/chat/completions",
                "requires_key": True
            },
            "anthropic": {
                "name": "Claude 3.5 Sonnet", 
                "endpoint": "https://api.anthropic.com/v1/messages",
                "requires_key": True
            },
            "local": {
                "name": "Ollama Local",
                "endpoint": "http://localhost:11434/api/chat",
                "requires_key": False
            }
        }
        
        # Configuration par d√©faut
        self.selected_model = None
        self.api_key = None
        
    def configure_model(self, model_type: str, api_key: Optional[str] = None):
        """Configure le mod√®le LLM √† utiliser"""
        if model_type in self.available_models:
            self.selected_model = model_type
            self.api_key = api_key
            return True
        return False
    
    def is_configured(self) -> bool:
        """V√©rifie si le mod√®le est configur√©"""
        if not self.selected_model:
            return False
        
        model_info = self.available_models[self.selected_model]
        if model_info["requires_key"] and not self.api_key:
            return False
            
        return True
    
    def analyze_data_with_llm(self, question: str, data_summary: Dict[str, Any]) -> str:
        """Analyse les donn√©es avec le LLM"""
        if not self.is_configured():
            return self._fallback_analysis(question, data_summary)
        
        try:
            # Construire le prompt intelligent
            system_prompt = self._build_system_prompt()
            user_prompt = self._build_user_prompt(question, data_summary)
            
            # Appeler le mod√®le appropri√©
            if self.selected_model == "openai":
                return self._call_openai(system_prompt, user_prompt)
            elif self.selected_model == "anthropic":
                return self._call_anthropic(system_prompt, user_prompt)
            elif self.selected_model == "local":
                return self._call_ollama(system_prompt, user_prompt)
            else:
                return self._fallback_analysis(question, data_summary)
                
        except Exception as e:
            st.error(f"‚ùå Erreur LLM: {str(e)}")
            return self._fallback_analysis(question, data_summary)
    
    def _build_system_prompt(self) -> str:
        """Construit le prompt syst√®me"""
        return """Tu es un assistant IA expert en analyse de donn√©es financi√®res et commerciales.

CONTEXTE: Tu analyses des donn√©es de souscriptions, ventes, et performance commerciale pour une entreprise financi√®re.

DONN√âES DISPONIBLES: Tu recevras un r√©sum√© des donn√©es avec des m√©triques cl√©s.

INSTRUCTIONS:
1. R√©ponds en fran√ßais de mani√®re professionnelle
2. Utilise des emojis pour structurer tes r√©ponses (üìä üí∞ üë• üìà etc.)
3. Fournis des chiffres pr√©cis quand disponibles
4. Donne des insights et recommandations pertinentes
5. Sois concis mais informatif (max 300 mots)
6. Utilise des formats structur√©s avec des puces
7. Ajoute des recommandations d'actions si pertinent

STYLE: Direct, analytique, avec des insights business."""
    
    def _build_user_prompt(self, question: str, data_summary: Dict[str, Any]) -> str:
        """Construit le prompt utilisateur avec les donn√©es"""
        prompt = f"""QUESTION: {question}

R√âSUM√â DES DONN√âES:
"""
        
        for key, value in data_summary.items():
            if isinstance(value, (int, float)):
                prompt += f"‚Ä¢ {key}: {value:,}\n" if isinstance(value, int) else f"‚Ä¢ {key}: {value:,.2f}\n"
            else:
                prompt += f"‚Ä¢ {key}: {value}\n"
        
        prompt += "\nAnalyse ces donn√©es et r√©ponds √† la question avec des insights pertinents."
        return prompt
    
    def _call_openai(self, system_prompt: str, user_prompt: str) -> str:
        """Appelle l'API OpenAI"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "gpt-4o-mini",  # Mod√®le plus √©conomique
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "max_tokens": 500,
            "temperature": 0.3
        }
        
        response = requests.post(self.available_models["openai"]["endpoint"], 
                               headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"]
        else:
            raise Exception(f"API Error: {response.status_code}")
    
    def _call_anthropic(self, system_prompt: str, user_prompt: str) -> str:
        """Appelle l'API Anthropic"""
        headers = {
            "x-api-key": self.api_key,
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01"
        }
        
        data = {
            "model": "claude-3-5-sonnet-20241022",
            "max_tokens": 500,
            "system": system_prompt,
            "messages": [{"role": "user", "content": user_prompt}]
        }
        
        response = requests.post(self.available_models["anthropic"]["endpoint"],
                               headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            return response.json()["content"][0]["text"]
        else:
            raise Exception(f"API Error: {response.status_code}")
    
    def _call_ollama(self, system_prompt: str, user_prompt: str) -> str:
        """Appelle Ollama en local"""
        data = {
            "model": "llama3.2",  # ou autre mod√®le local
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "stream": False
        }
        
        response = requests.post(self.available_models["local"]["endpoint"],
                               json=data, timeout=60)
        
        if response.status_code == 200:
            return response.json()["message"]["content"]
        else:
            raise Exception(f"Ollama Error: {response.status_code}")
    
    def _fallback_analysis(self, question: str, data_summary: Dict[str, Any]) -> str:
        """Analyse de secours sans LLM"""
        return f"""ü§ñ **Analyse des donn√©es** (Mode basique)

üìä **R√©sum√© des m√©triques disponibles:**
{chr(10).join([f"‚Ä¢ {k}: {v}" for k, v in data_summary.items()])}

üí° **Note:** Pour des analyses plus intelligentes et contextuelles, configurez un mod√®le LLM dans les param√®tres du chatbot.

Votre question: "{question}"
"""
    
    def test_model_connection(self, model_type: str, api_key: str = None) -> bool:
        """Teste la connexion au mod√®le LLM"""
        try:
            if model_type == "openai":
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }
                data = {
                    "model": "gpt-4o-mini",
                    "messages": [{"role": "user", "content": "Test"}],
                    "max_tokens": 5
                }
                response = requests.post(self.available_models["openai"]["endpoint"], 
                                       headers=headers, json=data, timeout=10)
                return response.status_code == 200
                
            elif model_type == "anthropic":
                headers = {
                    "x-api-key": api_key,
                    "Content-Type": "application/json",
                    "anthropic-version": "2023-06-01"
                }
                data = {
                    "model": "claude-3-5-sonnet-20241022",
                    "max_tokens": 5,
                    "messages": [{"role": "user", "content": "Test"}]
                }
                response = requests.post(self.available_models["anthropic"]["endpoint"],
                                       headers=headers, json=data, timeout=10)
                return response.status_code == 200
                
            elif model_type == "local":
                # Test simple de ping pour Ollama
                response = requests.get("http://localhost:11434/api/tags", timeout=5)
                return response.status_code == 200
                
        except Exception:
            return False
        
        return False

class DashboardApp:
    """Classe principale du dashboard commercial"""
    
    def __init__(self):
        """Initialisation de l'application"""
        self.setup_logging()
        self.setup_streamlit_config()
        self.setup_theme()
        
        # Variables d'√©tat pour les donn√©es
        self.data_files = {
            'df_epargne': None,
            'df_immo': None,
            'df_entretiens_epargne': None,
            'df_entretiens_immo': None,
            'df_rdv': None,
            'df_clients': None,
            'df_clients_analyse': None,  # Nouveau fichier pour l'analyse clients
            'df_analyse_2025': None,  # Nouveau fichier pour l'analyse 2025
            'df_paiements_epargne': None,
            'df_paiements_immo': None
        }
        
        # Initialize LLM Assistant
        self.llm_assistant = LLMAssistant()
        
        # Performance settings
        self.performance_mode = st.sidebar.checkbox(
            "‚ö° Mode Performance", 
            value=True, 
            help="Active l'optimisation des performances (cache, lazy loading)"
        )
        
        # Variable pour stocker les messages de traitement des donn√©es
        if 'data_processing_messages' not in st.session_state:
            st.session_state.data_processing_messages = []
    
    def setup_logging(self):
        """Configuration du syst√®me de logging"""
        if CONFIG_LOADED:
            config.configure_logging()
        else:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("Application Dashboard Commercial d√©marr√©e")
    
    def setup_streamlit_config(self):
        """Configuration de Streamlit"""
        if CONFIG_LOADED:
            #config.configure_streamlit()
            logging.info("Configuration config_loader d√©sactiv√©e temporairement")
        else:
            # Configuration par d√©faut
            #st.set_page_config(
            #    page_title="Dashboard Commercial",
            #    page_icon="üìä",
            #    layout="wide",
            #    initial_sidebar_state="expanded",
            #    menu_items={
            #        'Get Help': 'mailto:support@votredomaine.com',
            #        'Report a bug': 'https://gitlab.com/datanaly-group/dashboard-souscriptions/-/issues',
            #        'About': "Dashboard Commercial v2.0"
            #    }
            #)
            # Juste un message de log √† la place
            logging.info("Configuration Streamlit par d√©faut utilis√©e")
    
    def setup_theme(self):
        """Configuration du th√®me et des styles CSS"""
        if CONFIG_LOADED:
            theme_colors = get_theme_colors()
            chart_config = get_chart_config()
        else:
            theme_colors = {
                'primary_color': '#1f77b4',
                'background_color': '#ffffff',
                'secondary_background_color': '#13c2c2',
                'text_color': '#000000',
                'success_color': '#51cf66',
                'warning_color': '#ffd43b',
                'error_color': '#ff6b6b'
            }
            chart_config = {'default_height': 400}
        
        # CSS personnalis√© avec les couleurs du th√®me
        st.markdown(f"""
        <style>
            /* Styles principaux */
            .main-header {{
                color: {theme_colors.get('primary_color', '#1f77b4')};
                font-size: 3rem;
                text-align: center;
                margin-bottom: 2rem;
                font-weight: 700;
            }}
            
            .sub-header {{
                color: {theme_colors.get('primary_color', '#1f77b4')};
                font-size: 2rem;
                margin-bottom: 1rem;
                border-bottom: 2px solid {theme_colors.get('primary_color', '#1f77b4')};
                padding-bottom: 0.5rem;
            }}
            
            /* Cartes m√©triques */
            .metric-card {{
                background: linear-gradient(135deg, {theme_colors.get('secondary_background_color', '#13c2c2')}, #13c2c2);
                padding: 1.5rem;
                border-radius: 10px;
                border-left: 4px solid {theme_colors.get('primary_color', '#1f77b4')};
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                margin-bottom: 1rem;
            }}
            
            /* Status indicators */
            .status-success {{
                background-color: {theme_colors.get('success_color', '#51cf66')};
                color: white;
                padding: 0.5rem 1rem;
                border-radius: 20px;
                font-weight: bold;
                display: inline-block;
                margin: 0.2rem;
            }}
            
            .status-warning {{
                background-color: {theme_colors.get('warning_color', '#ffd43b')};
                color: #333;
                padding: 0.5rem 1rem;
                border-radius: 20px;
                font-weight: bold;
                display: inline-block;
                margin: 0.2rem;
            }}
            
            .status-error {{
                background-color: {theme_colors.get('error_color', '#ff6b6b')};
                color: white;
                padding: 0.5rem 1rem;
                border-radius: 20px;
                font-weight: bold;
                display: inline-block;
                margin: 0.2rem;
            }}
            
            /* Sidebar am√©lior√©e */
            .sidebar-section {{
                background-color: {theme_colors.get('secondary_background_color', '#13c2c2')};
                padding: 1rem;
                border-radius: 8px;
                margin-bottom: 1rem;
                border: 1px solid #e0e0e0;
            }}
            
            /* Onglets personnalis√©s - Bleu canard */
            .stTabs [data-baseweb="tab-list"] {{
                gap: 8px;
            }}
            
            .stTabs [data-baseweb="tab"] {{
                background-color: #E0F2F1;
                border-radius: 8px 8px 0 0;
                padding: 0.5rem 1rem;
                border: none;
                color: #008B8B;
                transition: all 0.3s ease;
            }}
            
            .stTabs [data-baseweb="tab"]:hover {{
                background-color: #B2DFDB;
                color: #006666;
            }}
            
            .stTabs [aria-selected="true"] {{
                background-color: #008B8B !important;
                color: white !important;
                font-weight: bold;
                box-shadow: 0 2px 4px rgba(0,139,139,0.3);
            }}
            
            /* Footer */
            .footer {{
                position: fixed;
                left: 0;
                bottom: 0;
                width: 100%;
                background-color: {theme_colors.get('primary_color', '#1f77b4')};
                color: white;
                text-align: center;
                padding: 10px;
                font-size: 0.8rem;
            }}
        </style>
        """, unsafe_allow_html=True)
    
    def render_header(self):
        """Affichage de l'en-t√™te de l'application"""
        app_name = get_config("app.name", "Dashboard Commercial") if CONFIG_LOADED else "Dashboard Commercial"
        app_version = get_config("app.version", "2.0") if CONFIG_LOADED else "2.0"
        
        st.markdown(f'<h1 class="main-header">{app_name}</h1>', unsafe_allow_html=True)
        
        # Informations syst√®me en colonnes
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            st.write("üìä Analyse des souscriptions, entretiens et rendez-vous")
        
        with col2:
            environment = get_config("deployment.environment", "development") if CONFIG_LOADED else "development"
            if environment == "production":
                st.success("üåê Environnement de production")
            else:
                st.info(f"üîß Environnement: {environment}")
        
        with col3:
            st.caption(f"Version {app_version}")
    
    def render_sidebar(self):
        """Affichage de la sidebar avec chargement des fichiers"""
        with st.sidebar:
            # Chatbot IA en haut
            self.render_sidebar_chatbot()
            
            st.markdown('<div class="sidebar-section">', unsafe_allow_html=True)
            st.header("üìÅ Information")
            st.markdown('</div>', unsafe_allow_html=True)
            
            st.info("üí° **Nouveau !** Les fichiers se chargent maintenant directement dans chaque page d'analyse pour plus de clart√©.")
            
            # Configuration des types de fichiers accept√©s pour r√©f√©rence
            accepted_formats = get_config("data.formats.upload", ["xlsx", "xls", "csv"]) if CONFIG_LOADED else ["xlsx", "xls", "csv"]
            max_file_size = get_config("data.formats.max_file_size", "2000MB") if CONFIG_LOADED else "2000MB"
            
            st.success(f"üìã **Formats support√©s:** {', '.join(accepted_formats)}\nüìè **Taille max:** {max_file_size}")
            
            # Section Souscriptions
            with st.expander("üí∞ Souscriptions", expanded=True):
                st.markdown("**üìä Donn√©es de souscriptions pour analyses financi√®res**")
                
                # √âpargne
                st.markdown("**üè¶ √âpargne**")
                st.caption("Colonnes attendues: Date de souscription, Montant, Conseiller, Produit, Statut/√âtape")
                self.data_files['df_epargne'] = self.load_file(
                    "üìà Souscriptions √©pargne", 
                    "file_epargne",
                    accepted_formats,
                    description="Fichier des souscriptions d'√©pargne avec montants et conseillers"
                )
                
                # Immobilier
                st.markdown("**üè† Immobilier**")
                st.caption("Colonnes attendues: Date de cr√©ation, Conseiller, Statut, Montant, Type de bien")
                self.data_files['df_immo'] = self.load_file(
                    "üèòÔ∏è Souscriptions immobili√®res", 
                    "file_immo",
                    accepted_formats,
                    description="Fichier des dossiers immobiliers avec statuts et conseillers"
                )
            
            # Section Entretiens
            with st.expander("üó£Ô∏è Entretiens", expanded=True):
                st.markdown("**üìû Donn√©es d'entretiens clients pour analyses de performance**")
                
                # Entretiens √âpargne
                st.markdown("**üíº Entretiens √âpargne**")
                st.caption("Colonnes attendues: Date, Conseiller, Type d'entretien, R√©sultat, Client")
                self.data_files['df_entretiens_epargne'] = self.load_file(
                    "üìã Entretiens √©pargne", 
                    "file_entretiens_epargne",
                    accepted_formats,
                    process_entretiens=True,
                    type_entretien="√âpargne",
                    description="Fichier des entretiens clients pour l'√©pargne"
                )
                
                # Entretiens Immobilier
                st.markdown("**üèóÔ∏è Entretiens Immobilier**")
                st.caption("Colonnes attendues: Date, Conseiller, Type d'entretien, R√©sultat, Client")
                self.data_files['df_entretiens_immo'] = self.load_file(
                    "üèòÔ∏è Entretiens immobiliers", 
                    "file_entretiens_immo",
                    accepted_formats,
                    process_entretiens=True,
                    type_entretien="Immobilier",
                    description="Fichier des entretiens clients pour l'immobilier"
                )
            
            # Section RDV et Clients
            with st.expander("üìÖ RDV et Clients", expanded=True):
                st.markdown("**üë• Donn√©es de rendez-vous et informations clients**")
                
                # RDV
                st.markdown("**üìÜ Rendez-vous**")
                st.caption("Colonnes attendues: Date RDV, Conseiller, Type RDV, Statut, Client")
                self.data_files['df_rdv'] = self.load_file(
                    "üïê Fichier des RDV", 
                    "file_rdv",
                    accepted_formats,
                    description="Planning et suivi des rendez-vous clients"
                )
                
                # Clients
                st.markdown("**üë§ Base clients**")
                st.caption("Colonnes attendues: Nom, Pr√©nom, Email, T√©l√©phone, Conseiller affect√©")
                self.data_files['df_clients'] = self.load_file(
                    "üìá Base de donn√©es clients", 
                    "file_clients",
                    accepted_formats,
                    description="Informations et parcours des clients"
                )
                
                # Analyse clients
                st.markdown("**üìä Analyse clients d√©taill√©e**")
                st.caption("Colonnes: Nom & Pr√©nom, Email, Date entretien, Nb Souscriptions, VR, M√©tier, Secteur, Revenus, TMI, Profil √©pargnant, etc.")
                self.data_files['df_clients_analyse'] = self.load_file(
                    "üéØ Fichier d'analyse clients", 
                    "file_clients_analyse",
                    accepted_formats,
                    description="Donn√©es d√©taill√©es des clients pour analyse approfondie"
                )
                
                # Analyse 2025
                st.markdown("**üöÄ Analyse 2025**")
                st.caption("Colonnes: Full Name, Email, Phone, Mobile, Profession, Contact Owner, Opportunit√© Name, Produit, Premier versement, Stage, Date versement initial, Date validation 570, Date de passage comit√©, Apport net")
                self.data_files['df_analyse_2025'] = self.load_file(
                    "üöÄ Fichier d'analyse 2025", 
                    "file_analyse_2025",
                    accepted_formats,
                    description="Donn√©es 2025 avec pipeline commercial et opportunit√©s"
                )
            
            # Section Paiements
            with st.expander("üí∏ Paiements", expanded=True):
                st.markdown("**üí≥ Donn√©es de paiements et transactions financi√®res**")
                
                # Paiements √âpargne
                st.markdown("**üí∞ Paiements √âpargne**")
                st.caption("Colonnes attendues: Date paiement, Montant, Conseiller, Statut, R√©f√©rence")
                self.data_files['df_paiements_epargne'] = self.load_file(
                    "üíµ Paiements √©pargne", 
                    "file_paiements_epargne",
                    accepted_formats,
                    description="Suivi des paiements et encaissements √©pargne"
                )
                
                # Paiements Immobilier
                st.markdown("**üè¶ Paiements Immobilier**")
                st.caption("Colonnes attendues: Date paiement, Montant, Conseiller, Statut, R√©f√©rence")
                self.data_files['df_paiements_immo'] = self.load_file(
                    "üè† Paiements immobiliers", 
                    "file_paiements_immo",
                    accepted_formats,
                    description="Suivi des paiements et commissions immobilier"
                )
            
            # Statut global des fichiers
            st.markdown("---")
            self.render_file_status()
            
            # Informations syst√®me
            st.markdown("---")
            self.render_system_info()
    
    @staticmethod
    @st.cache_data(ttl=300, show_spinner=False)  # Cache for 5 minutes
    def _process_uploaded_file(_file_content, _file_name, process_entretiens=False, type_entretien=None):
        """Process uploaded file with caching and memory optimization - internal method"""
        import io
        df = read_excel_robust(io.BytesIO(_file_content))
        
        if df is not None:
            # Memory optimization: reduce data types where possible
            try:
                df = DashboardApp._optimize_dataframe_memory(df)
            except Exception as e:
                # If optimization fails, continue with original DataFrame
                pass
            
            if process_entretiens and type_entretien:
                # Renommer la colonne "Date de cr√©ation" en "Date" si elle existe
                if "Date de cr√©ation" in df.columns:
                    df = df.rename(columns={"Date de cr√©ation": "Date"})
                # Ajouter une colonne Type
                df["Type"] = type_entretien
            
        return df
    
    @staticmethod
    def _optimize_dataframe_memory(df):
        """Optimize DataFrame memory usage by converting data types"""
        import pandas as pd
        
        for col in df.columns:
            try:
                # Convert object columns that are actually numeric
                if df[col].dtype == 'object':
                    # Try to convert to numeric if it looks numeric
                    numeric_conversion = pd.to_numeric(df[col], errors='coerce')
                    if numeric_conversion.notna().sum() > len(df) * 0.5:  # If >50% are numeric
                        # Use smaller int types where possible
                        if numeric_conversion.min() >= 0 and numeric_conversion.max() <= 255:
                            df[col] = numeric_conversion.astype('Int8')
                        elif numeric_conversion.min() >= -128 and numeric_conversion.max() <= 127:
                            df[col] = numeric_conversion.astype('Int8')
                        elif numeric_conversion.min() >= 0 and numeric_conversion.max() <= 65535:
                            df[col] = numeric_conversion.astype('Int16')
                        else:
                            df[col] = numeric_conversion.astype('Int32')
                    else:
                        # For string columns, use category if many duplicates
                        if df[col].nunique() / len(df) < 0.5:  # If <50% unique values
                            df[col] = df[col].astype('category')
            except Exception:
                # Skip optimization for this column if it fails
                continue
        
        return df
    
    def load_file(self, label, key, formats, process_entretiens=False, type_entretien=None, description=None):
        """Chargement d'un fichier avec traitement sp√©cifique et mise en cache"""
        # Afficher la description si fournie
        if description:
            st.caption(f"‚ÑπÔ∏è {description}")
        
        # Diagnostic de la configuration de taille
        try:
            from streamlit.runtime.config import get_option
            max_size = get_option("server.maxUploadSize")
            st.caption(f"‚ÑπÔ∏è Taille max autoris√©e: {max_size}MB")
        except:
            st.caption("‚ÑπÔ∏è Configuration par d√©faut")
            
        file = st.file_uploader(label, type=formats, key=key)
        
        if file is not None:
            try:
                with st.spinner(f"Chargement de {label.lower()}..."):
                    # Use cached processing if performance mode is enabled
                    if self.performance_mode:
                        df = DashboardApp._process_uploaded_file(
                            file.getvalue(), 
                            file.name, 
                            process_entretiens=process_entretiens, 
                            type_entretien=type_entretien
                        )
                    else:
                        # Direct processing without caching for lighter memory usage
                        df = read_excel_robust(file)
                        
                        if df is not None and process_entretiens and type_entretien:
                            # Renommer la colonne "Date de cr√©ation" en "Date" si elle existe
                            if "Date de cr√©ation" in df.columns:
                                df = df.rename(columns={"Date de cr√©ation": "Date"})
                            # Ajouter une colonne Type
                            df["Type"] = type_entretien
                    
                    if df is not None:
                        # Affichage am√©lior√© du succ√®s
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.success(f"‚úÖ **{label}** charg√© avec succ√®s")
                        with col2:
                            st.metric("Lignes", f"{len(df):,}")
                        
                        # Afficher un aper√ßu des colonnes avec un toggle
                        if st.checkbox("üîç Voir les colonnes d√©tect√©es", key=f"cols_{key}"):
                            cols_preview = list(df.columns)[:10]  # Premi√®re 10 colonnes
                            if len(df.columns) > 10:
                                cols_preview.append(f"... et {len(df.columns) - 10} autres")
                            st.write("üìã **Colonnes d√©tect√©es:**")
                            for col in cols_preview:
                                st.write(f"‚Ä¢ {col}")
                        
                        self.logger.info(f"Fichier charg√©: {label} - {len(df)} lignes")
                        return df
                    else:
                        st.error(f"‚ùå Erreur lors du chargement de {label.lower()}")
                        self.logger.error(f"Erreur chargement: {label}")
                        return None
            except Exception as e:
                st.error(f"‚ùå **Erreur:** {str(e)}")
                self.logger.error(f"Exception lors du chargement {label}: {e}")
                return None
        
        return None
    
    def process_entretiens_file(self, df, type_entretien):
        """Traitement sp√©cifique des fichiers d'entretiens"""
        # Renommer la colonne "Date de cr√©ation" en "Date" si elle existe
        if "Date de cr√©ation" in df.columns:
            df = df.rename(columns={"Date de cr√©ation": "Date"})
        
        # Ajouter une colonne Type
        df["Type"] = type_entretien
        
        return df
    
    def render_file_status(self):
        """Affichage du statut global des fichiers charg√©s"""
        st.subheader("üìä Statut des fichiers")
        
        # D√©finir les cat√©gories de fichiers avec leurs ic√¥nes
        file_categories = {
            "üí∞ Souscriptions": {
                "df_epargne": "üè¶ √âpargne",
                "df_immo": "üè† Immobilier"
            },
            "üó£Ô∏è Entretiens": {
                "df_entretiens_epargne": "üíº √âpargne",
                "df_entretiens_immo": "üèóÔ∏è Immobilier"
            },
            "üìÖ RDV & Clients": {
                "df_rdv": "üïê RDV",
                "df_clients": "üë§ Clients",
                "df_clients_analyse": "üéØ Analyse clients",
                "df_analyse_2025": "üöÄ Analyse 2025"
            },
            "üí∏ Paiements": {
                "df_paiements_epargne": "üí∞ √âpargne",
                "df_paiements_immo": "üè¶ Immobilier"
            }
        }
        
        # Afficher le statut par cat√©gorie
        for category, files in file_categories.items():
            st.markdown(f"**{category}**")
            
            for file_key, file_name in files.items():
                df = self.data_files.get(file_key)
                if df is not None:
                    col1, col2, col3 = st.columns([2, 1, 1])
                    with col1:
                        st.success(f"‚úÖ {file_name}")
                    with col2:
                        st.caption(f"{len(df):,} lignes")
                    with col3:
                        st.caption(f"{len(df.columns)} colonnes")
                else:
                    st.error(f"‚ùå {file_name}")
            
            st.write("")  # Espacement
        
        # R√©sum√© global
        loaded_files = sum(1 for df in self.data_files.values() if df is not None)
        total_files = len(self.data_files)
        total_rows = sum(len(df) for df in self.data_files.values() if df is not None)
        
        st.markdown("**üìà R√©sum√© global**")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Fichiers", f"{loaded_files}/{total_files}")
        with col2:
            st.metric("Total lignes", f"{total_rows:,}" if total_rows > 0 else "0")
        with col3:
            completion_rate = (loaded_files / total_files) * 100
            st.metric("Compl√©tude", f"{completion_rate:.0f}%")
        
        # Indicateur de progression
        progress = loaded_files / total_files
        st.progress(progress)
        
        if loaded_files == total_files:
            st.success("üéâ Tous les fichiers sont charg√©s !")
        elif loaded_files > 0:
            st.info(f"üìã {total_files - loaded_files} fichier(s) restant(s) √† charger")
        else:
            st.warning("‚ö†Ô∏è Aucun fichier charg√©")
    
    def render_system_info(self):
        """Affichage des informations syst√®me"""
        st.subheader("‚ÑπÔ∏è Informations syst√®me")
        
        # Derni√®re mise √† jour
        now = datetime.now()
        st.write(f"üïí Derni√®re mise √† jour : {now.strftime('%d/%m/%Y %H:%M:%S')}")        
        # Statistiques des fichiers charg√©s
        loaded_files = sum(1 for df in self.data_files.values() if df is not None)
        total_files = len(self.data_files)
        st.metric("Fichiers charg√©s", f"{loaded_files}/{total_files}")
        
        # Total des lignes
        total_rows = sum(len(df) for df in self.data_files.values() if df is not None)
        if total_rows > 0:
            st.metric("Total lignes", f"{total_rows:,}")
        
        # Bouton pour vider le cache Streamlit
        st.markdown("---")
        st.subheader("üîÑ Rafra√Æchissement")
        col1, col2 = st.columns([1, 3])
        with col1:
            if st.button("üßπ Vider le cache", type="primary"):
                st.cache_data.clear()
                st.cache_resource.clear()
                st.rerun()
        with col2:
            st.caption("Utilisez ce bouton si vous rencontrez des probl√®mes d'affichage ou si les modifications de code ne sont pas prises en compte.")
        
        # Environnement
        if CONFIG_LOADED:
            env = get_config("deployment.environment", "development")
            domain = get_config("deployment.domain", "localhost")
            st.caption(f"üåê Env: {env}")
            if env == "production":
                st.caption(f"üîó {domain}")
    
    def render_file_status_overview(self):
        """Affichage de l'√©tat des fichiers dans l'accueil"""
        st.subheader("üìä √âtat des fichiers")
        
        # Cr√©er un DataFrame pour l'√©tat des fichiers
        file_status = []
        file_labels = {
            'df_epargne': 'Souscriptions √©pargne',
            'df_immo': 'Souscriptions immobili√®res',
            'df_entretiens_epargne': 'Entretiens √©pargne',
            'df_entretiens_immo': 'Entretiens immobiliers',
            'df_rdv': 'Rendez-vous',
            'df_clients': 'Clients',
            'df_clients_analyse': 'Analyse clients',
            'df_analyse_2025': 'Analyse 2025',
            'df_paiements_epargne': 'Paiements √©pargne',
            'df_paiements_immo': 'Paiements immobiliers'
        }
        
        for key, label in file_labels.items():
            df = self.data_files[key]
            status = "‚úÖ Charg√©" if df is not None else "‚ùå Non charg√©"
            rows = len(df) if df is not None else 0
            file_status.append({
                'Fichier': label,
                'Statut': status,
                'Lignes': f"{rows:,}" if rows > 0 else "-"
            })
        
        # Affichage en colonnes
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**üìÅ Souscriptions**")
            for item in file_status[:2]:
                status_class = "status-success" if "‚úÖ" in item['Statut'] else "status-error"
                st.markdown(f"""
                <div class="metric-card">
                    <strong>{item['Fichier']}</strong><br>
                    <span class="{status_class}">{item['Statut']}</span><br>
                    <small>Lignes: {item['Lignes']}</small>
                </div>
                """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("**üó£Ô∏è Entretiens et RDV**")
            for item in file_status[2:5]:
                status_class = "status-success" if "‚úÖ" in item['Statut'] else "status-error"
                st.markdown(f"""
                <div class="metric-card">
                    <strong>{item['Fichier']}</strong><br>
                    <span class="{status_class}">{item['Statut']}</span><br>
                    <small>Lignes: {item['Lignes']}</small>
                </div>
                """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("**üë• Clients et Paiements**")
            for item in file_status[5:]:
                status_class = "status-success" if "‚úÖ" in item['Statut'] else "status-error"
                st.markdown(f"""
                <div class="metric-card">
                    <strong>{item['Fichier']}</strong><br>
                    <span class="{status_class}">{item['Statut']}</span><br>
                    <small>Lignes: {item['Lignes']}</small>
                </div>
                """, unsafe_allow_html=True)
            
        # Ajout d'une option pour analyser les paiements combin√©s
        st.markdown("---")
        st.subheader("üîó Analyse combin√©e des paiements")
        
        has_epargne = self.data_files['df_paiements_epargne'] is not None
        has_immo = self.data_files['df_paiements_immo'] is not None
        
        if has_epargne and has_immo:
            if st.button("üìä Analyser tous les paiements (√âpargne + Immobilier)", type="primary"):
                with st.expander("üí∏ Analyse combin√©e des paiements", expanded=True):
                    df_paiements_combined = pd.concat([
                        self.data_files['df_paiements_epargne'], 
                        self.data_files['df_paiements_immo']
                    ], ignore_index=True)
                    st.info("üìä Analyse combin√©e des paiements √©pargne et immobiliers")
                    analyser_paiements(df_paiements_combined)
        elif has_epargne or has_immo:
            st.info("‚ÑπÔ∏è Chargez les deux fichiers de paiements pour une analyse combin√©e")
        else:
            st.warning("‚ö†Ô∏è Aucun fichier de paiement charg√©")
    
    def render_welcome_tab(self):
        """Onglet d'accueil"""
        st.markdown('<h2 class="sub-header">üè† Accueil</h2>', unsafe_allow_html=True)
        
        # Description de l'application
        st.markdown("""
        ## Bienvenue dans le Dashboard Commercial 2.0
        
        Ce dashboard vous permet d'analyser en d√©tail les donn√©es commerciales de votre entreprise avec une interface moderne et des fonctionnalit√©s avanc√©es.
        
        ### üéØ Fonctionnalit√©s principales :
        
        - **üí∞ √âpargne** : Analyse compl√®te des souscriptions d'√©pargne
        - **üè¢ Immobilier** : Suivi d√©taill√© des souscriptions immobili√®res  
        - **üó£Ô∏è Entretiens** : Analyse des entretiens par type (√©pargne/immobilier)
        - **üìÖ RDV** : Gestion et analyse des rendez-vous
        - **üîÑ Conversions** : Calcul des taux de conversion inter-fichiers
        - **üë£ Parcours Client** : Analyse du parcours et comportement client
        - **üéØ Analyse Clients** : Analyse approfondie des donn√©es clients
        - **üí∏ Paiements √âpargne** : Suivi sp√©cialis√© des paiements √©pargne
        - **üí∏ Paiements Immobilier** : Suivi sp√©cialis√© des paiements immobiliers
        - **üìä Retard Cumul√©** : Suivi des objectifs annuels et retard cumul√©
        - **üë§ Clients D√©taill√©s** : Analyse avanc√©e et segmentation des clients
        
        ### üöÄ Nouveaut√©s v2.0 :
        - Configuration centralis√©e
        - Interface am√©lior√©e avec th√®me personnalisable
        - Logging et monitoring int√©gr√©s
        - Gestion d'erreurs renforc√©e
        - Performance optimis√©e
        """)
        
        # √âtat des fichiers avec style am√©lior√©
        self.render_file_status_overview()
        
        # Statistiques rapides si des donn√©es sont charg√©es
        self.render_quick_stats()
    
    def render_quick_stats(self):
        """Affichage de statistiques rapides"""
        loaded_data = [df for df in self.data_files.values() if df is not None]
        
        if loaded_data:
            st.subheader("üìà Statistiques rapides")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_rows = sum(len(df) for df in loaded_data)
                st.metric("Total enregistrements", f"{total_rows:,}")
            
            with col2:
                files_loaded = len(loaded_data)
                st.metric("Fichiers charg√©s", files_loaded)
            
            with col3:
                # Calculer le nombre de colonnes moyen
                avg_cols = sum(len(df.columns) for df in loaded_data) // len(loaded_data)
                st.metric("Colonnes moyennes", avg_cols)
            
            with col4:
                # Taille m√©moire approximative
                memory_mb = sum(df.memory_usage(deep=True).sum() for df in loaded_data) / (1024 * 1024)
                st.metric("M√©moire utilis√©e", f"{memory_mb:.1f} MB")
    
    def render_debug_info(self, tab_name=""):
        """Affiche les informations de d√©bogage √† la fin de chaque onglet"""
        st.markdown("---")
        
        with st.expander("üêõ Informations de D√©bogage", expanded=False):
            debug_col1, debug_col2, debug_col3 = st.columns(3)
            
            with debug_col1:
                st.subheader("üìä √âtat des Donn√©es")
                
                # √âtat des fichiers charg√©s
                files_status = {}
                for key, df in self.data_files.items():
                    if df is not None:
                        files_status[key] = {
                            "status": "‚úÖ Charg√©",
                            "rows": len(df),
                            "columns": len(df.columns),
                            "memory": f"{df.memory_usage(deep=True).sum() / (1024 * 1024):.1f} MB"
                        }
                    else:
                        files_status[key] = {
                            "status": "‚ùå Non charg√©",
                            "rows": 0,
                            "columns": 0,
                            "memory": "0 MB"
                        }
                
                st.json(files_status)
            
            with debug_col2:
                st.subheader("üîß Configuration Syst√®me")
                
                system_info = {
                    "tab_actuel": tab_name,
                    "config_loaded": CONFIG_LOADED,
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    "total_memory_used": f"{sum(df.memory_usage(deep=True).sum() for df in self.data_files.values() if df is not None) / (1024 * 1024):.1f} MB",
                    "files_loaded": sum(1 for df in self.data_files.values() if df is not None),
                    "total_records": sum(len(df) for df in self.data_files.values() if df is not None)
                }
                
                st.json(system_info)
            
            with debug_col3:
                st.subheader("üìã Colonnes D√©tect√©es")
                
                # Affichage des colonnes pour les fichiers charg√©s
                columns_info = {}
                for key, df in self.data_files.items():
                    if df is not None:
                        columns_info[key] = list(df.columns)[:10]  # Premi√®res 10 colonnes
                        if len(df.columns) > 10:
                            columns_info[key].append(f"... et {len(df.columns) - 10} autres")
                
                if columns_info:
                    st.json(columns_info)
                else:
                    st.info("Aucun fichier charg√©")
            
            # Messages de traitement des donn√©es
            st.subheader("üìã Messages de Traitement des Donn√©es")
            
            # Afficher les messages stock√©s dans session_state
            if hasattr(st.session_state, 'data_processing_messages') and st.session_state.data_processing_messages:
                st.markdown("**Messages de conversion et traitement :**")
                
                # Grouper les messages par type
                success_messages = []
                info_messages = []
                warning_messages = []
                error_messages = []
                
                for msg in st.session_state.data_processing_messages:
                    if msg.startswith("‚úÖ"):
                        success_messages.append(msg)
                    elif msg.startswith("‚ÑπÔ∏è"):
                        info_messages.append(msg)
                    elif msg.startswith("‚ö†Ô∏è"):
                        warning_messages.append(msg)
                    elif msg.startswith("‚ùå"):
                        error_messages.append(msg)
                
                # Afficher les messages group√©s
                for msg in success_messages:
                    st.success(msg)
                for msg in info_messages:
                    st.info(msg)
                for msg in warning_messages:
                    st.warning(msg)
                for msg in error_messages:
                    st.error(msg)
                
                # Bouton pour vider les messages
                if st.button("üßπ Vider les Messages", key=f"clear_messages_{tab_name}"):
                    st.session_state.data_processing_messages = []
                    st.success("Messages vid√©s !")
                    st.rerun()
            else:
                st.info("Aucun message de traitement des donn√©es disponible")
            
            # Section avanc√©e de d√©bogage
            st.subheader("üî¨ D√©bogage Avanc√©")
            
            debug_advanced_col1, debug_advanced_col2 = st.columns(2)
            
            with debug_advanced_col1:
                if st.button("üßπ Vider le Cache Streamlit", key=f"clear_cache_{tab_name}"):
                    st.cache_data.clear()
                    st.cache_resource.clear()
                    st.success("Cache vid√© !")
                    st.rerun()
                
                if st.button("üîÑ Recharger la Page", key=f"reload_{tab_name}"):
                    st.rerun()
            
            with debug_advanced_col2:
                if st.button("üíæ Export √âtat Debug", key=f"export_debug_{tab_name}"):
                    debug_export = {
                        "timestamp": datetime.now().isoformat(),
                        "tab": tab_name,
                        "files_status": files_status,
                        "system_info": system_info,
                        "columns_info": columns_info,
                        "processing_messages": getattr(st.session_state, 'data_processing_messages', [])
                    }
                    
                    debug_json = str(debug_export).encode('utf-8')
                    st.download_button(
                        label="üì• T√©l√©charger Debug JSON",
                        data=debug_json,
                        file_name=f"debug_dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain",
                        key=f"download_debug_{tab_name}"
                    )
    
    def render_tabs(self):
        """Affichage des onglets principaux avec lazy loading"""
        # Configuration des onglets
        tab_names = [
            "üè† Accueil",
            "üí∞ √âpargne", 
            "üè¢ Immobilier",
            "üìû Entretiens",
            "üîÑ Conversions",
            "üë• Parcours Client",
            "üéØ Analyse Clients",
            "üí≥ Paiements",
            "üìä Retard Cumul√©",
            "üë§ Clients D√©taill√©s",
            "üöÄ Analyse 2025",
            "ü§ñ Chatbot IA"
        ]
        
        # Use selectbox instead of tabs for better performance (only active tab renders)
        selected_tab = st.selectbox(
            "üìä S√©lectionner une analyse:",
            tab_names,
            index=0,
            key="main_tab_selector"
        )
        
        # Add a visual separator
        st.markdown("---")
        
        # Render only the selected tab content
        if selected_tab == "üè† Accueil":
            self.render_welcome_tab()
            self.render_debug_info("Accueil")
        
        elif selected_tab == "üí∞ √âpargne":
            st.markdown('<h2 class="sub-header">üí∞ Analyse √âpargne</h2>', unsafe_allow_html=True)
            
            # Chargement du fichier sp√©cifique √† cette analyse
            st.subheader("üìÅ Chargement des donn√©es")
            df_epargne = self.load_file(
                "üìà Fichier souscriptions √©pargne", 
                "file_epargne_tab",
                ["xlsx", "csv"],
                description="Colonnes attendues: Date de souscription, Montant, Conseiller, Produit, Statut/√âtape"
            )


# =============================================================================

            if df_epargne is None:
                df_epargne = auto_load_from_s3("epargne", description="souscriptions √©pargne")
# =============================================================================


            if df_epargne is not None:
                st.markdown("---")
                
                # Cr√©er des sous-onglets pour l'analyse √©pargne
                epargne_subtab = st.selectbox(
                    "üìä Type d'analyse √©pargne:",
                    ["Performance Globale", "Performance par Conseiller", "Analyse par Groupe", "Pipe de Collecte"],
                    key="epargne_subtab"
                )
                
                st.markdown("---")
                
                if epargne_subtab == "Performance Globale":
                    with st.spinner("üìä Analyse de la performance globale..."):
                        analyser_souscriptions_epargne(df_epargne)
                elif epargne_subtab == "Performance par Conseiller":
                    with st.spinner("üìä Analyse par conseiller..."):
                        analyser_performance_conseillers_epargne(df_epargne)
                elif epargne_subtab == "Analyse par Groupe":
                    with st.spinner("üìä Analyse par groupe..."):
                        analyser_groupes_epargne(df_epargne)
                elif epargne_subtab == "Pipe de Collecte":
                    with st.spinner("üìä Analyse du pipe de collecte..."):
                        analyser_pipe_collecte_epargne(df_epargne)
            
                self.render_debug_info("√âpargne")


# =============================================================================
#           if df_epargne is None:
#                 df_epargne = make_epargne_from_crypto(df)
#                 if not df_epargne.empty:
#                     st.info("üß™ Mode test : donn√©es crypto (Lightsail) mapp√©es vers √âpargne.")
#                     st.markdown("---")
                
#                     # Cr√©er des sous-onglets pour l'analyse √©pargne
#                     epargne_subtab = st.selectbox(
#                         "üìä Type d'analyse √©pargne:",
#                         ["Performance Globale", "Performance par Conseiller", "Analyse par Groupe", "Pipe de Collecte"],
#                         key="epargne_subtab"
#                     )
                    
#                     st.markdown("---")
                    
#                     if epargne_subtab == "Performance Globale":
#                         with st.spinner("üìä Analyse de la performance globale..."):
#                             analyser_souscriptions_epargne(df_epargne)
#                     elif epargne_subtab == "Performance par Conseiller":
#                         with st.spinner("üìä Analyse par conseiller..."):
#                             analyser_performance_conseillers_epargne(df_epargne)
#                     elif epargne_subtab == "Analyse par Groupe":
#                         with st.spinner("üìä Analyse par groupe..."):
#                             analyser_groupes_epargne(df_epargne)
#                     elif epargne_subtab == "Pipe de Collecte":
#                         with st.spinner("üìä Analyse du pipe de collecte..."):
#                             analyser_pipe_collecte_epargne(df_epargne)
                
#                 self.render_debug_info("√âpargne")
                # =============================================================================



            elif selected_tab == "üè¢ Immobilier":
                st.markdown('<h2 class="sub-header">üè¢ Analyse Immobilier</h2>', unsafe_allow_html=True)
                
                # Chargement du fichier sp√©cifique √† cette analyse
                st.subheader("üìÅ Chargement des donn√©es")
                df_immo = self.load_file(
                    "üè† Fichier souscriptions immobili√®res", 
                    "file_immo_tab",
                    ["xlsx", "csv"],
                    description="Colonnes attendues: Date de cr√©ation, Conseiller, Statut, Montant, Type de bien"
                )

# =============================================================================

            if df_immo is None:
                df_immo = auto_load_from_s3("immo", description="souscriptions immobili√®res")
# =============================================================================




            if df_immo is not None:
                st.markdown("---")
                
                # Cr√©er des sous-onglets pour l'analyse immobili√®re
                immo_subtab = st.selectbox(
                    "üè¢ Type d'analyse immobilier:",
                    ["Suivi Global", "Analyse par Statut", "Analyse par Groupe"],
                    key="immo_subtab"
                )
                
                st.markdown("---")
                
                if immo_subtab == "Suivi Global":
                    with st.spinner("üè¢ Analyse du suivi global..."):
                        analyser_suivi_immo(df_immo)
                elif immo_subtab == "Analyse par Statut":
                    with st.spinner("üè¢ Analyse par statut..."):
                        analyser_statuts_dossiers_immo(df_immo)
                elif immo_subtab == "Analyse par Groupe":
                    with st.spinner("üè¢ Analyse par groupe..."):
                        analyser_groupes_dossiers_immo(df_immo)
            
            self.render_debug_info("Immobilier")
                # =============================================================================
#             if df_immo is None:
#                 df_immo = make_immo_from_crypto(df)
#                 if not df_immo.empty:
#                     st.info("üß™ Mode test : donn√©es crypto (Lightsail) mapp√©es vers Immobilier.")
#                     st.markdown("---")
                
#                     # Cr√©er des sous-onglets pour l'analyse immobili√®re
#                     immo_subtab = st.selectbox(
#                         "üè¢ Type d'analyse immobilier:",
#                         ["Suivi Global", "Analyse par Statut", "Analyse par Groupe"],
#                         key="immo_subtab"
#                         )
                        
#                     st.markdown("---")
                        
#                     if immo_subtab == "Suivi Global":
#                         with st.spinner("üè¢ Analyse du suivi global..."):
#                             analyser_suivi_immo(df_immo)
#                     elif immo_subtab == "Analyse par Statut":
#                         with st.spinner("üè¢ Analyse par statut..."):
#                             analyser_statuts_dossiers_immo(df_immo)
#                     elif immo_subtab == "Analyse par Groupe":
#                         with st.spinner("üè¢ Analyse par groupe..."):
#                             analyser_groupes_dossiers_immo(df_immo)

  
#             self.render_debug_info("Immobilier")
                

               # =============================================================================

        
        elif selected_tab == "üìû Entretiens":
            with st.spinner("üìû Chargement des analyses d'entretiens..."):
                self.render_entretiens_tab()
            self.render_debug_info("Entretiens")
        
        elif selected_tab == "üîÑ Conversions":
            with st.spinner("üîÑ Calcul des taux de conversion..."):
                self.render_conversions_tab()
            self.render_debug_info("Conversions")
        
        elif selected_tab == "üë• Parcours Client":
            st.markdown('<h2 class="sub-header">üë• Analyse Parcours Client</h2>', unsafe_allow_html=True)
            
            # Chargement du fichier sp√©cifique √† cette analyse
            st.subheader("üìÅ Chargement des donn√©es")
            df_clients = self.load_file(
                "üìá Base de donn√©es clients", 
                "file_clients_tab",
                ["xlsx", "csv"],
                description="Colonnes attendues: Nom, Pr√©nom, Email, T√©l√©phone, Conseiller affect√©"
            )
            
            if df_clients is not None:
                st.markdown("---")
                with st.spinner("üë• Analyse du parcours client..."):
                    analyser_parcours_client(df_clients)
            
            self.render_debug_info("Parcours Client")
        
        elif selected_tab == "üéØ Analyse Clients":
            st.markdown('<h2 class="sub-header">üéØ Analyse Clients D√©taill√©e</h2>', unsafe_allow_html=True)
            
            st.subheader("üìÅ Chargement des donn√©es - Analyse Clients")
            df_clients_analyse = self.load_file(
                "üìä Fichier analyse clients d√©taill√©e", 
                "file_analyse_clients_tab",
                ["xlsx", "csv"],
                description="Colonnes attendues: Nom & Pr√©nom, Email, Date de l'entretien, Nb Souscriptions, VR, M√©tier, Secteur d'activit√©, Revenus, etc."
            )
            
            if df_clients_analyse is not None:
                st.markdown("---")
                with st.spinner("üéØ Analyse d√©taill√©e des clients..."):
                    analyser_clients(df_clients_analyse)
            else:
                st.info("üí° Chargez le fichier d'analyse clients pour voir les analyses d√©taill√©es.")
            
            self.render_debug_info("Analyse Clients")
        
        elif selected_tab == "üí≥ Paiements":
            paiement_type = st.selectbox(
                "üí≥ Type de paiement:",
                ["Paiements √âpargne", "Paiements Immobilier"],
                key="paiement_subtab"
            )
            
            st.markdown("---")
            
            if paiement_type == "Paiements √âpargne":
                # Chargement de fichier pour les paiements √©pargne
                df_paiements_epargne = self.load_file(
                    "Upload du fichier paiements √©pargne", 
                    "paiements_epargne",
                    "Chargez le fichier Excel des paiements √©pargne pour analyser les transactions et les tendances de versements."
                )
                
                if df_paiements_epargne is not None:
                    with st.spinner("üí≥ Analyse des paiements √©pargne..."):
                        analyser_paiements(df_paiements_epargne, "√©pargne")
                else:
                    st.warning("‚ö†Ô∏è Veuillez charger le fichier des paiements √©pargne.")
            else:
                # Chargement de fichier pour les paiements immobilier
                df_paiements_immo = self.load_file(
                    "Upload du fichier paiements immobilier", 
                    "paiements_immo",
                    "Chargez le fichier Excel des paiements immobilier pour analyser les transactions et les versements immobiliers."
                )
                
                if df_paiements_immo is not None:
                    with st.spinner("üí≥ Analyse des paiements immobilier..."):
                        analyser_paiements(df_paiements_immo, "immobilier")
                else:
                    st.warning("‚ö†Ô∏è Veuillez charger le fichier des paiements immobiliers.")
            
            self.render_debug_info("Paiements")
        
        elif selected_tab == "üìä Retard Cumul√©":
            st.markdown('<h2 class="sub-header">üìä Retard Cumul√© par Rapport √† l\'Objectif Annuel</h2>', unsafe_allow_html=True)
            st.info("üí° Cette section analyse le retard cumul√© depuis le d√©but de l'ann√©e par rapport √† l'objectif annuel de 22M‚Ç¨, avec un objectif mensuel de 1,83M‚Ç¨.")
            
            st.subheader("üìÅ Chargement des donn√©es - √âpargne")
            df_epargne_retard = self.load_file(
                "üí∞ Fichier souscriptions √©pargne", 
                "file_epargne_retard_tab",
                ["xlsx", "csv"],
                description="Colonnes attendues: Date de souscription, Montant, Conseiller pour calculer le retard cumul√©"
            )
            
            if df_epargne_retard is not None:
                st.markdown("---")
                with st.spinner("üìä Calcul du retard cumul√©..."):
                    self.analyser_retard_cumule(df_epargne_retard)
            else:
                st.info("üí° Chargez le fichier des souscriptions √©pargne pour analyser le retard cumul√©.")
            
            self.render_debug_info("Retard Cumul√©")
        
        elif selected_tab == "üë§ Clients D√©taill√©s":
            st.markdown('<h2 class="sub-header">üë§ Analyse D√©taill√©e des Clients</h2>', unsafe_allow_html=True)
            st.info("üí° Cette section propose une analyse approfondie des donn√©es clients avec des fonctionnalit√©s de segmentation et de profilage avanc√©es bas√©es sur vos colonnes Excel sp√©cifiques.")
            
            # Chargement de fichier pour cette analyse
            df_clients = self.load_file(
                "Upload du fichier clients d√©taill√©s", 
                "clients_analyse",
                "Chargez le fichier Excel contenant l'analyse d√©taill√©e des clients avec leurs profils professionnels et personnels."
            )
            
            if df_clients is not None:
                # Utiliser le nouveau module d'analyse int√©gr√©e
                with st.spinner("üë§ Analyse d√©taill√©e des clients en cours..."):
                    analyser_clients_integration(df_clients)
            else:
                st.warning("‚ö†Ô∏è Veuillez charger le fichier d'analyse clients d√©taill√©e.")
                
                # Afficher les colonnes attendues bas√©es sur l'image fournie
                st.markdown("### üìã Structure Attendue du Fichier Excel")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("""
                    **Informations de base :**
                    - Nom & Pr√©nom
                    - Email
                    - Date de l'entretien
                    - Nb Souscriptions
                    - Derni√®re Souscription
                    - VR (Versements R√©guliers - OUI/NON)
                    """)
                
                with col2:
                    st.markdown("""
                    **Profil professionnel :**
                    - M√©tier
                    - Secteur d'activit√©
                    - Revenus
                    - Type de contrat
                    - √âligibilit√©
                    - TMI (Tranche Marginale d'Imposition)
                    """)
                
                with col3:
                    st.markdown("""
                    **Profil personnel :**
                    - Profil √©pargnant
                    - √âpargne disponible
                    - Situation familiale
                    - Nb d'enfants
                    - Date d'inscription
                    - Conseiller
                    """)
                
                st.markdown("---")
                st.info("üîÑ **VR (Versements R√©guliers) :** Cette colonne indique si le client a des versements programm√©s. **OUI** = versements r√©guliers actifs, **NON** = pas de versements programm√©s.")
                
                st.success("‚ú® **Fonctionnalit√©s de l'analyse int√©gr√©e :**")
                
                feature_cols = st.columns(2)
                with feature_cols[0]:
                    st.markdown("""
                    üîç **Filtres avanc√©s :**
                    - Multi-crit√®res (conseiller, secteur, √©ligibilit√©, revenus)
                    - Plages de revenus personnalisables
                    - Filtrage par profil √©pargnant
                    
                    üìä **Analyses d√©taill√©es :**
                    - Vue d'ensemble avec graphiques interactifs
                    - Performance par conseiller
                    - R√©partition par secteur d'activit√©
                    - Matrice de corr√©lations financi√®res
                    """)
                
                with feature_cols[1]:
                    st.markdown("""
                    üéØ **Segmentation avanc√©e :**
                    - Classification automatique (Champions, Gros Potentiel, Tr√®s Actifs, Fid√®les, √Ä D√©velopper)
                    - Analyse familiale et d√©mographique
                    - √âvolution temporelle des entretiens
                    
                    üì§ **Exports & Rapports :**
                    - Export CSV avec donn√©es filtr√©es
                    - R√©sum√© statistique automatique
                    - Recommandations strat√©giques par segment
                    """)
            
            self.render_debug_info("Clients D√©taill√©s")
        
        elif selected_tab == "üöÄ Analyse 2025":
            st.markdown('<h2 class="sub-header">üöÄ Analyse 2025</h2>', unsafe_allow_html=True)
            st.info("üí° Cette section analyse les donn√©es avec les nouvelles colonnes 2025 pour le suivi des opportunit√©s et du pipeline commercial.")
            
            # Chargement de fichier pour l'analyse 2025
            df_analyse_2025 = self.load_file(
                "Upload du fichier analyse 2025", 
                "analyse_2025",
                ["xlsx", "xls", "csv"],
                description="Chargez le fichier Excel 2025 avec les colonnes Contact Owner, Opportunit√© Name, Stage, Premier versement, Apport net, etc."
            )
            
            if df_analyse_2025 is not None:
                # Sauvegarder dans session_state pour le chatbot
                st.session_state['chatbot_data_2025'] = df_analyse_2025
                
                with st.spinner("üöÄ Analyse des donn√©es 2025 en cours..."):
                    self.analyser_donnees_2025(df_analyse_2025)
                
                # Analyse de saisonnalit√© des ventes 2025
                st.markdown("---")
                with st.spinner("üìà Analyse de saisonnalit√© en cours..."):
                    self.analyser_saisonnalite_ventes(df_analyse_2025)
            else:
                st.warning("‚ö†Ô∏è Veuillez charger le fichier d'analyse 2025.")
                
                # Afficher la structure attendue
                st.markdown("### üìã Structure Attendue du Fichier Excel 2025")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("""
                    **Informations client :**
                    - Full Name
                    - Email
                    - Phone
                    - Mobile
                    - Profession
                    """)
                
                with col2:
                    st.markdown("""
                    **Gestion commerciale :**
                    - Contact Owner
                    - Opportunit√© Name
                    - Produit
                    - Stage
                    """)
                
                with col3:
                    st.markdown("""
                    **Donn√©es financi√®res & temporelles :**
                    - Premier versement
                    - Apport net
                    - Date versement initial
                    - Date validation 570
                    - Date de passage comit√©
                    """)
            
            self.render_debug_info("Analyse 2025")
        
        elif selected_tab == "ü§ñ Chatbot IA":
            self.render_chatbot_tab()
    
    def render_chatbot_tab(self):
        """Onglet Chatbot IA pour l'assistance directeur"""
        st.markdown('<h2 class="sub-header">ü§ñ Assistant IA - Questions sur les Analyses</h2>', unsafe_allow_html=True)
        st.info("üí° Posez vos questions sur les analyses et obtenez des r√©ponses avec les chiffres cl√©s correspondants")
        
        # Instructions d'utilisation
        with st.expander("üìã Comment utiliser l'Assistant IA", expanded=False):
            st.markdown("""
            ### üéØ **Questions que vous pouvez poser :**
            
            **üìä Analyses g√©n√©rales :**
            - "Quel est notre CA total pour 2024 ?"
            - "Combien de nouveaux clients avons-nous acquis cette ann√©e ?"
            - "Quel est notre top 3 des produits ?"
            
            **üë• Analyses par conseiller :**
            - "Qui est le meilleur conseiller en termes de CA ?"
            - "Combien de clients a Pierre ce mois-ci ?"
            
            **üìà Saisonnalit√© et tendances :**
            - "Quel trimestre est le plus performant ?"
            - "Comment √©voluent nos ventes SCPI ?"
            
            **üéØ Segmentation :**
            - "Combien de clients dans le segment CPP Actif ?"
            - "Quel est le panier moyen des clients IMMO ?"
            """)
        
        # Interface de chat
        st.subheader("üí¨ Posez votre question")
        
        # Historique de conversation
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        # Interface de saisie
        user_question = st.text_input(
            "Votre question :",
            placeholder="Ex: Quel est notre CA total pour 2024 ?",
            key="chatbot_input"
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            ask_button = st.button("ü§ñ Demander", type="primary")
        with col2:
            clear_button = st.button("üóëÔ∏è Effacer historique")
        
        if clear_button:
            st.session_state.chat_history = []
            st.rerun()
        
        # Traitement de la question
        if ask_button and user_question.strip():
            with st.spinner("üß† L'IA analyse vos donn√©es..."):
                response = self.process_ai_question(user_question)
                
                # Ajouter √† l'historique
                st.session_state.chat_history.append({
                    'question': user_question,
                    'response': response,
                    'timestamp': datetime.now().strftime("%H:%M:%S")
                })
        
        # Affichage de l'historique de conversation
        if st.session_state.chat_history:
            st.subheader("üìù Historique de conversation")
            
            for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):  # 5 derniers √©changes
                with st.container():
                    st.markdown(f"""
                    <div style="background-color: #f0f2f6; padding: 10px; border-radius: 10px; margin: 10px 0;">
                        <strong>üë§ Vous ({chat['timestamp']}) :</strong><br>
                        {chat['question']}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.markdown(f"""
                    <div style="background-color: #e8f4fd; padding: 10px; border-radius: 10px; margin: 10px 0;">
                        <strong>ü§ñ Assistant IA :</strong><br>
                        {chat['response']}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if i < len(st.session_state.chat_history[-5:]) - 1:
                        st.markdown("---")
        
        # Suggestions de questions
        st.subheader("üí° Questions sugg√©r√©es")
        
        suggestions = [
            "üìä Quel est notre CA total cette ann√©e ?",
            "üë• Combien de nouveaux clients en 2024 ?",
            "üèÜ Qui est le meilleur conseiller ?",
            "üìà Quel trimestre est le plus performant ?",
            "üéØ R√©partition des segments clients ?",
            "üí∞ Panier moyen par produit ?"
        ]
        
        cols = st.columns(2)
        for i, suggestion in enumerate(suggestions):
            with cols[i % 2]:
                if st.button(suggestion, key=f"suggestion_{i}"):
                    with st.spinner("üß† L'IA analyse vos donn√©es..."):
                        response = self.process_ai_question(suggestion.replace("üìä ", "").replace("üë• ", "").replace("üèÜ ", "").replace("üìà ", "").replace("üéØ ", "").replace("üí∞ ", ""))
                        
                        st.session_state.chat_history.append({
                            'question': suggestion,
                            'response': response,
                            'timestamp': datetime.now().strftime("%H:%M:%S")
                        })
                        st.rerun()
    
    def create_data_summary(self, available_data):
        """Cr√©e un r√©sum√© des donn√©es pour l'analyse LLM"""
        from datetime import datetime
        import pandas as pd
        import numpy as np
        
        summary = {}
        total_ca = 0
        total_clients = 0
        total_transactions = 0
        
        for key in available_data:
            df = self.data_files.get(key)
            if df is not None and len(df) > 0:
                # Informations g√©n√©rales
                summary[f"{key}_nombre_lignes"] = len(df)
                summary[f"{key}_nombre_colonnes"] = len(df.columns)
                
                # Analyser colonnes mon√©taires
                montant_cols = [col for col in df.columns if any(word in col.lower() for word in ['montant', 'premier', 'versement', 'ca', 'apport'])]
                if montant_cols:
                    try:
                        montant_col = montant_cols[0]
                        montants = pd.to_numeric(df[montant_col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce')
                        montants = montants.dropna()
                        if len(montants) > 0:
                            ca_total = montants.sum()
                            panier_moyen = montants.mean()
                            summary[f"{key}_ca_total"] = ca_total
                            summary[f"{key}_panier_moyen"] = panier_moyen
                            total_ca += ca_total
                            total_transactions += len(montants)
                    except:
                        pass
                
                # Analyser clients uniques
                if 'Email' in df.columns:
                    nb_clients = df['Email'].nunique()
                    summary[f"{key}_clients_uniques"] = nb_clients
                    total_clients += nb_clients
                
                # Analyser dates
                date_cols = [col for col in df.columns if any(word in col.lower() for word in ['date', 'versement', 'inscription'])]
                if date_cols:
                    try:
                        date_col = date_cols[0]
                        dates = pd.to_datetime(df[date_col], errors='coerce').dropna()
                        if len(dates) > 0:
                            summary[f"{key}_periode_debut"] = dates.min().strftime('%Y-%m-%d')
                            summary[f"{key}_periode_fin"] = dates.max().strftime('%Y-%m-%d')
                    except:
                        pass
                
                # Top produits/conseillers
                if 'Conseiller' in df.columns:
                    top_conseiller = df['Conseiller'].value_counts().head(3)
                    summary[f"{key}_top_conseillers"] = dict(top_conseiller)
                
                if 'Produit' in df.columns:
                    top_produit = df['Produit'].value_counts().head(3)
                    summary[f"{key}_top_produits"] = dict(top_produit)
        
        # R√©sum√© global
        if total_ca > 0:
            summary["ca_total_global"] = total_ca
        if total_clients > 0:
            summary["clients_total_global"] = total_clients
        if total_transactions > 0:
            summary["transactions_total_global"] = total_transactions
        
        return summary
    
    def process_ai_question(self, question):
        """Traite une question IA et retourne une r√©ponse bas√©e sur les donn√©es"""
        from datetime import datetime
        import pandas as pd
        import numpy as np
        
        question_lower = question.lower()
        
        # R√©ponses bas√©es sur les donn√©es charg√©es
        try:
            # V√©rifier quelles donn√©es sont disponibles
            available_data = []
            
            # V√©rifier data_files classiques
            for key, df in self.data_files.items():
                if df is not None and len(df) > 0:
                    available_data.append(key)
            
            # Ajouter donn√©es sp√©cifiques du session_state
            if 'chatbot_data_2025' in st.session_state and st.session_state.chatbot_data_2025 is not None:
                # Copier temporairement pour l'analyse
                self.data_files['temp_analyse_2025'] = st.session_state.chatbot_data_2025
                available_data.append('temp_analyse_2025')
            
            if 'chatbot_data_epargne' in st.session_state and st.session_state.chatbot_data_epargne is not None:
                # Copier temporairement pour l'analyse
                self.data_files['temp_epargne'] = st.session_state.chatbot_data_epargne
                available_data.append('temp_epargne')
            
            all_data = available_data
            
            if not all_data:
                return """‚ùå **Aucune donn√©e charg√©e**

üí° **Comment obtenir des r√©ponses pr√©cises :**

**Option 1 - Chargement dans le chatbot :**
‚Ä¢ Utilisez le widget 'Chargement rapide pour IA' ci-dessus
‚Ä¢ Chargez votre fichier principal (ex: analyse 2025)

**Option 2 - Chargement par page :**
‚Ä¢ Allez dans l'onglet d'analyse souhait√©
‚Ä¢ Chargez le fichier correspondant
‚Ä¢ Revenez poser votre question

**Exemple de questions que je peux traiter :**
‚Ä¢ "Quel est notre CA total 2024 ?"
‚Ä¢ "Combien de clients CPP Actif ?"
‚Ä¢ "Top 3 des conseillers par CA"
‚Ä¢ "√âvolution par trimestre"
"""
            
            # Analyser la question et g√©n√©rer une r√©ponse
            response = "ü§ñ **Analyse en cours...**\n\n"
            
            # Essayer d'abord l'analyse LLM si configur√©e
            llm_response = None
            try:
                # V√©rifier si un LLM est configur√©
                configured_model = None
                configured_key = None
                
                for model in self.llm_assistant.available_models.keys():
                    if st.session_state.get(f'llm_configured_{model}', False):
                        configured_model = model
                        configured_key = st.session_state.get(f'llm_key_{model}')
                        break
                
                if configured_model:
                    # Configurer le LLM assistant
                    self.llm_assistant.configure_model(configured_model, configured_key)
                    
                    # Cr√©er r√©sum√© des donn√©es pour le LLM
                    data_summary = self.create_data_summary(all_data)
                    
                    # Obtenir l'analyse LLM
                    llm_response = self.llm_assistant.analyze_data_with_llm(question, data_summary)
                    
                    if llm_response and llm_response.strip():
                        response = llm_response
                        response += f"\n\nüìã **Sources utilis√©es :** {', '.join(all_data)}"
                        response += f"\nü§ñ **Analyse IA :** {self.llm_assistant.available_models[configured_model]['name']}"
                        response += f"\nüïí **Analyse effectu√©e le :** {datetime.now().strftime('%d/%m/%Y √† %H:%M')}"
                        
                        # Nettoyer les donn√©es temporaires
                        for key in list(self.data_files.keys()):
                            if key.startswith('temp_'):
                                del self.data_files[key]
                        
                        return response
            
            except Exception as e:
                # Si erreur avec LLM, continuer avec analyse basique
                st.warning(f"‚ö†Ô∏è Erreur avec l'IA configur√©e : {str(e)}")
                pass
            
            # Fallback vers analyse basique si pas d'LLM ou erreur
            # Questions sur le CA / Chiffre d'affaires
            if any(word in question_lower for word in ['ca', 'chiffre', 'affaires', 'revenus', 'montant']):
                response += self.analyze_ca_data()
            
            # Questions sur les clients
            elif any(word in question_lower for word in ['client', 'nouveaux', 'acquisition']):
                response += self.analyze_client_data()
            
            # Questions sur les conseillers
            elif any(word in question_lower for word in ['conseiller', 'commercial', 'vendeur', 'meilleur']):
                response += self.analyze_conseiller_data()
            
            # Questions sur les produits
            elif any(word in question_lower for word in ['produit', 'top', 'meilleur', 'scpi', 'per', 'immo']):
                response += self.analyze_produit_data()
            
            # Questions sur la saisonnalit√©
            elif any(word in question_lower for word in ['trimestre', 'saison', 'mois', 'tendance', '√©volution']):
                response += self.analyze_seasonality_data()
            
            # Questions sur la segmentation
            elif any(word in question_lower for word in ['segment', 'cpp', 'pgp', 'mono', 'multi']):
                response += self.analyze_segmentation_data()
            
            else:
                response += self.generate_general_summary()
            
            # Ajouter les sources de donn√©es
            response += f"\n\nüìã **Sources utilis√©es :** {', '.join(all_data)}"
            response += f"\nüïí **Analyse effectu√©e le :** {datetime.now().strftime('%d/%m/%Y √† %H:%M')}"
            
            # Nettoyer les donn√©es temporaires
            for key in list(self.data_files.keys()):
                if key.startswith('temp_'):
                    del self.data_files[key]
            
            return response
            
        except Exception as e:
            # Nettoyer les donn√©es temporaires m√™me en cas d'erreur
            for key in list(self.data_files.keys()):
                if key.startswith('temp_'):
                    del self.data_files[key]
            return f"‚ùå **Erreur lors de l'analyse :** {str(e)}\n\nüí° Veuillez v√©rifier que vos donn√©es sont correctement charg√©es."
    
    def analyze_ca_data(self):
        """Analyse les donn√©es de CA"""
        response = "üí∞ **Analyse du Chiffre d'Affaires :**\n\n"
        
        for key, df in self.data_files.items():
            if df is not None and len(df) > 0:
                # Rechercher des colonnes de montant
                montant_cols = [col for col in df.columns if any(word in col.lower() for word in ['montant', 'premier', 'versement', 'ca', 'apport'])]
                
                if montant_cols:
                    try:
                        montant_col = montant_cols[0]
                        # Nettoyer et calculer
                        montants = pd.to_numeric(df[montant_col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce')
                        montants = montants.dropna()
                        
                        if len(montants) > 0:
                            ca_total = montants.sum()
                            nb_transactions = len(montants)
                            panier_moyen = montants.mean()
                            
                            response += f"üìä **{key}** :\n"
                            response += f"- CA Total : **{ca_total:,.0f}‚Ç¨**\n"
                            response += f"- Nombre de transactions : **{nb_transactions:,}**\n"
                            response += f"- Panier moyen : **{panier_moyen:,.0f}‚Ç¨**\n\n"
                    except:
                        continue
        
        if "üìä" not in response:
            response += "‚ÑπÔ∏è Aucune donn√©e financi√®re trouv√©e dans les fichiers charg√©s.\n"
        
        return response
    
    def analyze_client_data(self):
        """Analyse les donn√©es clients"""
        response = "üë• **Analyse des Clients :**\n\n"
        
        for key, df in self.data_files.items():
            if df is not None and len(df) > 0:
                if 'Email' in df.columns:
                    nb_clients_uniques = df['Email'].nunique()
                    nb_total_transactions = len(df)
                    
                    response += f"üìä **{key}** :\n"
                    response += f"- Clients uniques : **{nb_clients_uniques:,}**\n"
                    response += f"- Total transactions : **{nb_total_transactions:,}**\n"
                    
                    # Analyser l'acquisition par ann√©e si possible
                    date_cols = [col for col in df.columns if any(word in col.lower() for word in ['date', 'versement', 'inscription'])]
                    if date_cols:
                        try:
                            date_col = date_cols[0]
                            df_temp = df.copy()
                            df_temp['Date_Clean'] = pd.to_datetime(df_temp[date_col], errors='coerce')
                            df_temp = df_temp.dropna(subset=['Date_Clean'])
                            
                            if len(df_temp) > 0:
                                # Nouveaux clients par ann√©e
                                premiers_clients = df_temp.groupby('Email')['Date_Clean'].min()
                                acquisitions_par_annee = premiers_clients.dt.year.value_counts().sort_index()
                                
                                response += f"- Nouveaux clients 2024 : **{acquisitions_par_annee.get(2024, 0):,}**\n"
                                response += f"- Nouveaux clients 2023 : **{acquisitions_par_annee.get(2023, 0):,}**\n"
                        except:
                            pass
                    
                    response += "\n"
        
        if "üìä" not in response:
            response += "‚ÑπÔ∏è Aucune donn√©e client trouv√©e dans les fichiers charg√©s.\n"
        
        return response
    
    def analyze_conseiller_data(self):
        """Analyse les donn√©es conseillers"""
        response = "üë®‚Äçüíº **Analyse des Conseillers :**\n\n"
        
        for key, df in self.data_files.items():
            if df is not None and len(df) > 0:
                conseiller_cols = [col for col in df.columns if any(word in col.lower() for word in ['conseiller', 'owner', 'commercial', 'agent'])]
                
                if conseiller_cols:
                    try:
                        conseiller_col = conseiller_cols[0]
                        
                        # Top conseillers par nombre de transactions
                        top_conseillers = df[conseiller_col].value_counts().head(5)
                        
                        response += f"üèÜ **Top 5 Conseillers - {key}** :\n"
                        for i, (conseiller, nb) in enumerate(top_conseillers.items(), 1):
                            response += f"{i}. **{conseiller}** : {nb:,} transactions\n"
                        
                        # Si on a des montants, calculer le CA par conseiller
                        montant_cols = [col for col in df.columns if any(word in col.lower() for word in ['montant', 'premier', 'versement'])]
                        if montant_cols:
                            montant_col = montant_cols[0]
                            ca_par_conseiller = df.groupby(conseiller_col)[montant_col].apply(
                                lambda x: pd.to_numeric(x.astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce').sum()
                            ).sort_values(ascending=False).head(3)
                            
                            response += f"\nüí∞ **Top 3 CA - {key}** :\n"
                            for i, (conseiller, ca) in enumerate(ca_par_conseiller.items(), 1):
                                response += f"{i}. **{conseiller}** : {ca:,.0f}‚Ç¨\n"
                        
                        response += "\n"
                    except:
                        continue
        
        if "üèÜ" not in response:
            response += "‚ÑπÔ∏è Aucune donn√©e conseiller trouv√©e dans les fichiers charg√©s.\n"
        
        return response
    
    def analyze_produit_data(self):
        """Analyse les donn√©es produits"""
        response = "üè∑Ô∏è **Analyse des Produits :**\n\n"
        
        for key, df in self.data_files.items():
            if df is not None and len(df) > 0 and 'Produit' in df.columns:
                try:
                    # Top produits par volume
                    top_produits = df['Produit'].value_counts().head(5)
                    
                    response += f"üìä **Top 5 Produits - {key}** :\n"
                    for i, (produit, nb) in enumerate(top_produits.items(), 1):
                        response += f"{i}. **{produit}** : {nb:,} ventes\n"
                    
                    # CA par produit si disponible
                    montant_cols = [col for col in df.columns if any(word in col.lower() for word in ['montant', 'premier', 'versement'])]
                    if montant_cols:
                        montant_col = montant_cols[0]
                        ca_par_produit = df.groupby('Produit')[montant_col].apply(
                            lambda x: pd.to_numeric(x.astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce').sum()
                        ).sort_values(ascending=False).head(3)
                        
                        response += f"\nüí∞ **Top 3 CA par produit - {key}** :\n"
                        for i, (produit, ca) in enumerate(ca_par_produit.items(), 1):
                            response += f"{i}. **{produit}** : {ca:,.0f}‚Ç¨\n"
                    
                    response += "\n"
                except:
                    continue
        
        if "üìä" not in response:
            response += "‚ÑπÔ∏è Aucune donn√©e produit trouv√©e dans les fichiers charg√©s.\n"
        
        return response
    
    def analyze_seasonality_data(self):
        """Analyse la saisonnalit√©"""
        response = "üìà **Analyse de Saisonnalit√© :**\n\n"
        
        for key, df in self.data_files.items():
            if df is not None and len(df) > 0:
                date_cols = [col for col in df.columns if any(word in col.lower() for word in ['date', 'versement'])]
                
                if date_cols:
                    try:
                        date_col = date_cols[0]
                        df_temp = df.copy()
                        df_temp['Date_Clean'] = pd.to_datetime(df_temp[date_col], errors='coerce')
                        df_temp = df_temp.dropna(subset=['Date_Clean'])
                        
                        if len(df_temp) > 0:
                            # Analyse par trimestre
                            df_temp['Trimestre'] = df_temp['Date_Clean'].dt.quarter
                            ventes_par_trimestre = df_temp['Trimestre'].value_counts().sort_index()
                            
                            response += f"üóìÔ∏è **R√©partition trimestrielle - {key}** :\n"
                            trimestre_labels = {1: 'T1 (Hiver)', 2: 'T2 (Printemps)', 3: 'T3 (√ât√©)', 4: 'T4 (Automne)'}
                            for trimestre, nb in ventes_par_trimestre.items():
                                response += f"- **{trimestre_labels[trimestre]}** : {nb:,} ventes\n"
                            
                            meilleur_trimestre = ventes_par_trimestre.idxmax()
                            response += f"üèÜ **Meilleur trimestre** : {trimestre_labels[meilleur_trimestre]}\n\n"
                    except:
                        continue
        
        if "üóìÔ∏è" not in response:
            response += "‚ÑπÔ∏è Aucune donn√©e temporelle trouv√©e dans les fichiers charg√©s.\n"
        
        return response
    
    def analyze_segmentation_data(self):
        """Analyse les donn√©es de segmentation"""
        response = "üéØ **Analyse de Segmentation :**\n\n"
        
        # Cette fonction n√©cessiterait d'avoir acc√®s aux analyses de segmentation
        # Pour l'instant, on donne des informations g√©n√©rales
        response += "‚ÑπÔ∏è L'analyse de segmentation est disponible dans l'onglet 'üéØ Segmentation'.\n"
        response += "Vous y trouverez :\n"
        response += "- üè† **IMMO Mono-√©quip√©** : Clients avec uniquement produits IMMO\n"
        response += "- üü¢ **CPP Actif** : Gros potentiel >30k‚Ç¨ (actif 2024)\n"
        response += "- üü° **PGP+ Actif** : Moyen potentiel 10-30k‚Ç¨ (actif 2024)\n"
        response += "- üü† **PGP Actif** : Petit potentiel <10k‚Ç¨ (actif 2024)\n"
        response += "- üî¥ **CPP/PGP+ Inactifs** : Segments inactifs par taille de panier\n\n"
        response += "üí° Chargez vos donn√©es dans l'onglet 'üöÄ Analyse 2025' pour voir la segmentation d√©taill√©e.\n"
        
        return response
    
    def generate_general_summary(self):
        """G√©n√®re un r√©sum√© g√©n√©ral"""
        response = "üìä **R√©sum√© G√©n√©ral des Donn√©es :**\n\n"
        
        total_files = len([df for df in self.data_files.values() if df is not None])
        response += f"üìÅ **Fichiers charg√©s** : {total_files}\n\n"
        
        for key, df in self.data_files.items():
            if df is not None and len(df) > 0:
                response += f"üìà **{key}** :\n"
                response += f"- {len(df):,} lignes\n"
                response += f"- {len(df.columns)} colonnes\n"
                if 'Email' in df.columns:
                    response += f"- {df['Email'].nunique():,} clients uniques\n"
                response += "\n"
        
        response += "üí° **Posez des questions plus sp√©cifiques pour obtenir des analyses d√©taill√©es !**\n"
        
        return response
    
    def render_entretiens_tab(self):
        """Onglet des entretiens avec sous-onglets"""
        st.markdown('<h2 class="sub-header">üó£Ô∏è Analyse des Entretiens</h2>', unsafe_allow_html=True)
        
        entretiens_tabs = st.tabs(["Entretiens √âpargne", "Entretiens Immobiliers"])
        
        with entretiens_tabs[0]:
            st.subheader("üìÅ Chargement des donn√©es - Entretiens √âpargne")
            df_entretiens_epargne = self.load_file(
                "üìû Fichier entretiens √©pargne", 
                "file_entretiens_epargne_tab",
                ["xlsx", "csv"],
                description="Colonnes attendues: Date, Contact, Conseiller, Statut, Dur√©e, Type d'entretien"
            )
            
            if df_entretiens_epargne is not None:
                st.markdown("---")
                analyses.entretiens.analyser_entretiens_epargne(df_entretiens_epargne, None, None)
            else:
                st.info("üí° Chargez le fichier des entretiens √©pargne pour voir les analyses.")
        
        with entretiens_tabs[1]:
            st.subheader("üìÅ Chargement des donn√©es - Entretiens Immobiliers")
            df_entretiens_immo = self.load_file(
                "üè† Fichier entretiens immobiliers", 
                "file_entretiens_immo_tab",
                ["xlsx", "csv"],
                description="Colonnes attendues: Date, Contact, Conseiller, Statut, Type de bien, Dur√©e"
            )
            
            if df_entretiens_immo is not None:
                st.markdown("---")
                analyser_entretiens(df_entretiens_immo, key_suffix="_immo")
            else:
                st.info("üí° Chargez le fichier des entretiens immobiliers pour voir les analyses.")
    
    def render_conversions_tab(self):
        """Onglet des conversions avec liaison de donn√©es"""
        st.markdown('<h2 class="sub-header">üîÑ Analyse des Conversions</h2>', unsafe_allow_html=True)
        
        st.info("üí° Cette section lie les donn√©es de plusieurs fichiers (entretiens, RDV et souscriptions) pour calculer les taux de conversion.")
        
        conversion_tabs = st.tabs(["Conversion √âpargne", "Conversion Immobilier"])
        
        with conversion_tabs[0]:
            st.subheader("üìÅ Chargement des donn√©es - Conversion √âpargne")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                df_entretiens_epargne = self.load_file(
                    "üìû Entretiens √©pargne", 
                    "conv_entretiens_epargne",
                    ["xlsx", "csv"],
                    description="Fichier des entretiens √©pargne"
                )
            with col2:
                df_rdv_epargne = self.load_file(
                    "üìÖ RDV √©pargne", 
                    "conv_rdv_epargne",
                    ["xlsx", "csv"],
                    description="Fichier des RDV √©pargne"
                )
            with col3:
                df_souscriptions_epargne = self.load_file(
                    "üí∞ Souscriptions √©pargne", 
                    "conv_souscriptions_epargne",
                    ["xlsx", "csv"],
                    description="Fichier des souscriptions √©pargne"
                )
            
            if any([df_entretiens_epargne, df_rdv_epargne, df_souscriptions_epargne]):
                st.markdown("---")
                self.analyze_conversion(df_entretiens_epargne, df_rdv_epargne, df_souscriptions_epargne, "√©pargne")
            else:
                st.info("üí° Chargez au moins 2 fichiers parmi les 3 pour calculer les taux de conversion.")
        
        with conversion_tabs[1]:
            st.subheader("üìÅ Chargement des donn√©es - Conversion Immobilier")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                df_entretiens_immo = self.load_file(
                    "üè† Entretiens immo", 
                    "conv_entretiens_immo",
                    ["xlsx", "csv"],
                    description="Fichier des entretiens immobiliers"
                )
            with col2:
                df_rdv_immo = self.load_file(
                    "üìÖ RDV immo", 
                    "conv_rdv_immo",
                    ["xlsx", "csv"],
                    description="Fichier des RDV immobiliers"
                )
            with col3:
                df_souscriptions_immo = self.load_file(
                    "üè¢ Souscriptions immo", 
                    "conv_souscriptions_immo",
                    ["xlsx", "csv"],
                    description="Fichier des souscriptions immobili√®res"
                )
            
            if any([df_entretiens_immo, df_rdv_immo, df_souscriptions_immo]):
                st.markdown("---")
                self.analyze_conversion(df_entretiens_immo, df_rdv_immo, df_souscriptions_immo, "immobilier")
            else:
                st.info("üí° Chargez au moins 2 fichiers parmi les 3 pour calculer les taux de conversion.")
    
    def analyze_conversion(self, df_entretiens, df_rdv, df_souscriptions, type_conversion):
        """Analyse de conversion avec gestion des fichiers manquants"""
        files_available = [df for df in [df_entretiens, df_rdv, df_souscriptions] if df is not None]
        
        if len(files_available) >= 2:
            analyser_conversion(df_entretiens, df_rdv, df_souscriptions)
        elif len(files_available) == 1:
            st.warning(f"‚ö†Ô∏è Analyse limit√©e - seulement un fichier disponible pour la conversion {type_conversion}.")
            analyser_conversion(df_entretiens, df_rdv, df_souscriptions)
        else:
            st.error(f"‚ùå Veuillez charger au moins deux fichiers parmi : entretiens {type_conversion}, RDV et souscriptions {type_conversion}.")
    
    def analyser_retard_cumule(self, df):
        """Analyse et affiche le retard cumul√© par rapport √† l'objectif annuel.
        Calcule √©galement le retard sans les produits SOSK et BMSK.
        
        Args:
            df (DataFrame): DataFrame contenant les donn√©es de souscriptions
        """
        # S'assurer que les colonnes n√©cessaires existent
        if 'Date de souscription' not in df.columns or 'Montant du placement' not in df.columns:
            # Essayer de trouver des colonnes alternatives
            date_columns = [col for col in df.columns if 'date' in col.lower() or 'souscription' in col.lower()]
            montant_columns = [col for col in df.columns if 'montant' in col.lower() or 'placement' in col.lower() or 'collecte' in col.lower()]
            
            if date_columns and montant_columns:
                st.warning(f"‚ö†Ô∏è Colonnes standards non trouv√©es. Utilisation de {date_columns[0]} et {montant_columns[0]} √† la place.")
                date_column = date_columns[0]
                montant_column = montant_columns[0]
            else:
                st.error("‚ùå Les colonnes n√©cessaires pour l'analyse du retard cumul√© n'ont pas √©t√© trouv√©es.")
                st.info("Colonnes disponibles: " + ", ".join(df.columns.tolist()))
                return
        else:
            date_column = 'Date de souscription'
            montant_column = 'Montant du placement'
        
        # Identifier la colonne contenant le type de produit
        produit_column = None
        produit_candidates = ['Produit', 'Type de produit', 'Nom du produit', 'Product', 'Product Type']
        for col in produit_candidates:
            if col in df.columns:
                produit_column = col
                break
        
        # Si aucune colonne standard n'est trouv√©e, chercher des colonnes contenant des mots-cl√©s
        if produit_column is None:
            for col in df.columns:
                if 'produit' in col.lower() or 'product' in col.lower() or 'type' in col.lower():
                    produit_column = col
                    st.info(f"Utilisation de la colonne '{col}' pour identifier les produits.")
                    break
        
        # Convertir la date de souscription en datetime
        df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
        
        # Filtrer les lignes avec des dates valides
        df = df.dropna(subset=[date_column])
        
        # Ajouter une colonne pour l'ann√©e et le mois
        df['Ann√©e'] = df[date_column].dt.year
        df['Mois'] = df[date_column].dt.month
        
        # Obtenir l'ann√©e actuelle
        annee_actuelle = datetime.now().year
        
        # Filtrer les donn√©es pour l'ann√©e actuelle
        df_annee = df[df['Ann√©e'] == annee_actuelle].copy()
        
        if df_annee.empty:
            st.warning(f"‚ö†Ô∏è Aucune donn√©e disponible pour l'ann√©e {annee_actuelle}.")
            return
        
        # Obtenir le mois actuel
        mois_actuel = datetime.now().month
        
        # Calculer l'objectif proratis√© √† la date actuelle
        objectif_proratise = (OBJECTIF_ANNUEL_EPARGNE / 12) * mois_actuel
        
        # Calculer le montant total collect√© depuis le d√©but de l'ann√©e (tous produits)
        montant_collecte = df_annee[montant_column].sum()
        
        # Calculer le retard (ou l'avance) par rapport √† l'objectif
        retard = objectif_proratise - montant_collecte
        
        # Calcul sans les produits SOSK et BMSK
        df_sans_sosk_bmsk = df_annee.copy()
        if produit_column is not None:
            # Filtrer les produits SOSK et BMSK (recherche insensible √† la casse)
            mask_sosk_bmsk = df_annee[produit_column].astype(str).str.contains('SOSK|BMSK', case=False, regex=True)
            if mask_sosk_bmsk.any():
                df_sans_sosk_bmsk = df_annee[~mask_sosk_bmsk]
                montant_collecte_sans_sosk_bmsk = df_sans_sosk_bmsk[montant_column].sum()
                retard_sans_sosk_bmsk = objectif_proratise - montant_collecte_sans_sosk_bmsk
                
                # Calculer le montant des produits SOSK et BMSK
                montant_sosk_bmsk = montant_collecte - montant_collecte_sans_sosk_bmsk
            else:
                # Pas de produits SOSK ou BMSK trouv√©s
                montant_collecte_sans_sosk_bmsk = montant_collecte
                retard_sans_sosk_bmsk = retard
                montant_sosk_bmsk = 0
        else:
            # Pas de colonne produit identifi√©e
            montant_collecte_sans_sosk_bmsk = montant_collecte
            retard_sans_sosk_bmsk = retard
            montant_sosk_bmsk = 0
        
        # Afficher les m√©triques principales
        st.subheader("üí∞ Retard cumul√© - Tous produits")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Objectif annuel", f"{OBJECTIF_ANNUEL_EPARGNE/1_000_000:.1f}M‚Ç¨")
        with col2:
            st.metric("Objectif √† date", f"{objectif_proratise/1_000_000:.2f}M‚Ç¨")
        with col3:
            st.metric("Montant collect√©", f"{montant_collecte/1_000_000:.2f}M‚Ç¨")
        with col4:
            delta_label = "de retard" if retard > 0 else "d'avance"
            st.metric("√âcart", f"{abs(retard)/1_000_000:.2f}M‚Ç¨ {delta_label}", delta=-retard if retard > 0 else retard)
        
        # Afficher les m√©triques sans SOSK et BMSK
        st.subheader("üí≥ Retard cumul√© - Sans produits SOSK/BMSK")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Montant collect√©", f"{montant_collecte_sans_sosk_bmsk/1_000_000:.2f}M‚Ç¨")
        with col2:
            delta_label_sans_sosk = "de retard" if retard_sans_sosk_bmsk > 0 else "d'avance"
            st.metric("√âcart", f"{abs(retard_sans_sosk_bmsk)/1_000_000:.2f}M‚Ç¨ {delta_label_sans_sosk}", delta=-retard_sans_sosk_bmsk if retard_sans_sosk_bmsk > 0 else retard_sans_sosk_bmsk)
        with col3:
            st.metric("Montant SOSK/BMSK", f"{montant_sosk_bmsk/1_000_000:.2f}M‚Ç¨", delta=montant_sosk_bmsk)
        
        # Calculer le pourcentage de r√©alisation de l'objectif
        pourcentage_realisation = (montant_collecte / objectif_proratise) * 100
        
        # Cr√©er une jauge pour visualiser le pourcentage de r√©alisation
        fig = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=pourcentage_realisation,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Pourcentage de r√©alisation de l'objectif √† date"},
            delta={'reference': 100, 'increasing': {'color': "green"}, 'decreasing': {'color': "red"}},
            gauge={
                'axis': {'range': [0, 150], 'tickwidth': 1, 'tickcolor': "darkblue"},
                'bar': {'color': "darkblue"},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [0, 50], 'color': "red"},
                    {'range': [50, 75], 'color': "orange"},
                    {'range': [75, 100], 'color': "yellow"},
                    {'range': [100, 150], 'color': "green"}
                ],
                'threshold': {
                    'line': {'color': "black", 'width': 4},
                    'thickness': 0.75,
                    'value': 100
                }
            }
        ))
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Calculer l'√©volution mensuelle
        evolution_mensuelle = df_annee.groupby('Mois').agg(
            Montant=pd.NamedAgg(column=montant_column, aggfunc='sum')
        ).reset_index()
        
        # Ajouter le nom du mois
        evolution_mensuelle['Nom_Mois'] = evolution_mensuelle['Mois'].apply(lambda x: calendar.month_name[x])
        
        # Calculer le montant cumul√©
        evolution_mensuelle['Montant_Cumule'] = evolution_mensuelle['Montant'].cumsum()
        
        # Calculer l'objectif mensuel et l'objectif cumul√©
        evolution_mensuelle['Objectif_Mensuel'] = OBJECTIF_MENSUEL_EPARGNE
        evolution_mensuelle['Objectif_Cumule'] = evolution_mensuelle['Mois'].apply(lambda x: (OBJECTIF_ANNUEL_EPARGNE / 12) * x)
        
        # Calculer le retard cumul√©
        evolution_mensuelle['Retard_Cumule'] = evolution_mensuelle['Objectif_Cumule'] - evolution_mensuelle['Montant_Cumule']
        
        # Cr√©er un graphique pour visualiser l'√©volution du retard cumul√©
        fig_evolution = go.Figure()
        
        # Ajouter la ligne de montant cumul√©
        fig_evolution.add_trace(go.Scatter(
            x=evolution_mensuelle['Nom_Mois'],
            y=evolution_mensuelle['Montant_Cumule'],
            mode='lines+markers',
            name='Montant Cumul√©',
            line=dict(color='blue', width=3)
        ))
        
        # Ajouter la ligne d'objectif cumul√©
        fig_evolution.add_trace(go.Scatter(
            x=evolution_mensuelle['Nom_Mois'],
            y=evolution_mensuelle['Objectif_Cumule'],
            mode='lines+markers',
            name='Objectif Cumul√©',
            line=dict(color='green', width=3, dash='dash')
        ))
        
        # Ajouter des barres pour le retard cumul√©
        fig_evolution.add_trace(go.Bar(
            x=evolution_mensuelle['Nom_Mois'],
            y=evolution_mensuelle['Retard_Cumule'],
            name='Retard Cumul√©',
            marker_color=['red' if x > 0 else 'green' for x in evolution_mensuelle['Retard_Cumule']]
        ))
        
        fig_evolution.update_layout(
            title="üìà √âvolution du Retard Cumul√© par Rapport √† l'Objectif Annuel",
            xaxis_title="Mois",
            yaxis_title="Montant (‚Ç¨)",
            height=600,
            legend=dict(
                title="",
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            xaxis=dict(tickangle=45)
        )
        
        st.plotly_chart(fig_evolution, use_container_width=True)
        
        # Afficher le tableau d√©taill√©
        st.subheader("üìã D√©tail Mensuel")
        
        # Pr√©parer le tableau pour l'affichage
        tableau = evolution_mensuelle.copy()
        tableau['Nom_Mois'] = tableau['Mois'].apply(lambda x: calendar.month_name[x])
        tableau['Montant'] = tableau['Montant'].apply(lambda x: f"{x:,.0f}‚Ç¨")
        tableau['Montant_Cumule'] = tableau['Montant_Cumule'].apply(lambda x: f"{x:,.0f}‚Ç¨")
        tableau['Objectif_Mensuel'] = tableau['Objectif_Mensuel'].apply(lambda x: f"{x:,.0f}‚Ç¨")
        tableau['Objectif_Cumule'] = tableau['Objectif_Cumule'].apply(lambda x: f"{x:,.0f}‚Ç¨")
        tableau['Retard_Cumule'] = tableau['Retard_Cumule'].apply(lambda x: f"{x:,.0f}‚Ç¨")
        
        # Renommer les colonnes pour l'affichage
        tableau = tableau[['Nom_Mois', 'Montant', 'Montant_Cumule', 'Objectif_Mensuel', 'Objectif_Cumule', 'Retard_Cumule']]
        tableau.columns = ['Mois', 'Montant Mensuel', 'Montant Cumul√©', 'Objectif Mensuel', 'Objectif Cumul√©', 'Retard Cumul√©']
        
        st.dataframe(tableau, use_container_width=True)
        
        # T√©l√©chargement des donn√©es
        csv = tableau.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger les donn√©es (CSV)",
            data=csv,
            file_name=f"retard_cumule_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
    
    def analyser_donnees_2025(self, df):
        """Analyse sp√©cialis√©e pour les donn√©es 2025 avec pipeline commercial"""
        st.subheader("üéØ Vue d'Ensemble Pipeline 2025")
        
        if df is None or df.empty:
            st.error("‚ùå Aucune donn√©e disponible pour l'analyse 2025")
            return
        
        # Pr√©paration des donn√©es - regroupement par email
        df_clean = self.preparer_donnees_2025(df)
        
        # Premi√®re ligne de m√©triques - Informations g√©n√©rales
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("üìä Total Lignes", f"{len(df):,}")
        
        with col2:
            emails_uniques = df_clean['Email'].nunique() if 'Email' in df_clean.columns else len(df_clean)
            st.metric("üë• Clients Uniques", f"{emails_uniques:,}", 
                     help="Bas√© sur les emails uniques")
        
        with col3:
            if 'Contact Owner' in df_clean.columns:
                owners_uniques = df_clean['Contact Owner'].nunique()
                st.metric("üë®‚Äçüíº Contact Owners", f"{owners_uniques}")
            else:
                st.metric("üë®‚Äçüíº Contact Owners", "N/A")
        
        with col4:
            if 'Produit' in df_clean.columns:
                produits_uniques = df_clean['Produit'].nunique()
                st.metric("üì¶ Produits", f"{produits_uniques}")
            else:
                st.metric("üì¶ Produits", "N/A")
        
        with col5:
            if 'Stage' in df_clean.columns:
                stages_uniques = df_clean['Stage'].nunique()
                st.metric("üìä Stages", f"{stages_uniques}")
            else:
                st.metric("üìä Stages", "N/A")
        
        # Deuxi√®me ligne de m√©triques - Donn√©es financi√®res
        if any(col in df_clean.columns for col in ['Premier versement', 'Apport net']):
            st.subheader("üí∞ M√©triques Financi√®res")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                if 'Premier versement' in df_clean.columns:
                    # Convertir en num√©rique et calculer
                    from utils.data_processing_debug import safe_to_numeric_debug
                    premiers_versements = safe_to_numeric_debug(df_clean['Premier versement'])
                    if not premiers_versements.isna().all():
                        total_premiers = premiers_versements.sum()
                        st.metric("üí∏ Total Premiers Versements", f"{total_premiers:,.0f}‚Ç¨")
                    else:
                        st.metric("üí∏ Total Premiers Versements", "N/A")
                else:
                    st.metric("üí∏ Total Premiers Versements", "N/A")
            
            with col2:
                if 'Apport net' in df_clean.columns:
                    apports_nets = safe_to_numeric_debug(df_clean['Apport net'])
                    if not apports_nets.isna().all():
                        total_apports = apports_nets.sum()
                        st.metric("üè¶ Total Apports Nets", f"{total_apports:,.0f}‚Ç¨")
                    else:
                        st.metric("üè¶ Total Apports Nets", "N/A")
                else:
                    st.metric("üè¶ Total Apports Nets", "N/A")
            
            with col3:
                if 'Premier versement' in df_clean.columns:
                    clients_avec_versement = (premiers_versements > 0).sum()
                    pourcentage_versement = (clients_avec_versement / len(df_clean)) * 100
                    st.metric("üìà % avec Versement", f"{pourcentage_versement:.1f}%")
                else:
                    st.metric("üìà % avec Versement", "N/A")
            
            with col4:
                if 'Profession' in df_clean.columns:
                    professions_uniques = df_clean['Profession'].nunique()
                    st.metric("üíº Professions", f"{professions_uniques}")
                else:
                    st.metric("üíº Professions", "N/A")
        
        # Afficher les statistiques de regroupement
        if 'Email' in df.columns and len(df) != len(df_clean):
            doublons = len(df) - len(df_clean)
            st.info(f"‚ÑπÔ∏è {doublons:,} doublons d√©tect√©s et regroup√©s par email. Analyse bas√©e sur {len(df_clean):,} clients uniques.")
        
        # Analyses organis√©es par cat√©gories - 2 niveaux de navigation
        st.markdown("### üéØ Choisissez votre analyse :")
        
        # Premi√®re rang√©e d'onglets - Analyses principales
        main_tabs = st.tabs([
            "üìä Analyses Pipeline", 
            "üë• Analyses Clients",
            "üéØ Segmentation",
            "üì§ Export"
        ])
        
        with main_tabs[0]:  # Analyses Pipeline
            pipeline_subtabs = st.tabs([
                "üìä Pipeline par Stage",
                "üë®‚Äçüíº Contact Owners", 
                "üì¶ Produits",
                "üí∞ Financi√®re"
            ])
            
            with pipeline_subtabs[0]:
                self.analyser_pipeline_stages(df_clean)
            
            with pipeline_subtabs[1]:
                self.analyser_par_contact_owner(df_clean)
            
            with pipeline_subtabs[2]:
                self.analyser_par_produit(df_clean)
            
            with pipeline_subtabs[3]:
                self.analyser_financier_2025(df_clean)
        
        with main_tabs[1]:  # Analyses Clients
            client_subtabs = st.tabs([
                "üíº Professions",
                "üìÖ Temporel",
                "üí∞ Hors Immo"
            ])
            
            with client_subtabs[0]:
                self.analyser_professions(df_clean)
            
            with client_subtabs[1]:
                self.analyser_suivi_temporel_2025(df_clean)
            
            with client_subtabs[2]:
                self.analyser_opportunites(df_clean)
        
        with main_tabs[2]:  # Segmentation
            segmentation_subtabs = st.tabs([
                "üéØ Multi-√©quipement",
                "üè† Segmentation 7 Segments"
            ])
            
            with segmentation_subtabs[0]:
                self.analyser_multi_equipement(df_clean)
            
            with segmentation_subtabs[1]:
                self.analyser_segmentation_immo(df_clean)
        
        with main_tabs[3]:  # Export
            self.generer_export_2025(df_clean)
    
    def preparer_donnees_2025(self, df):
        """Pr√©pare et nettoie les donn√©es 2025 en regroupant par email"""
        import pandas as pd
        import numpy as np
        
        df_clean = df.copy()
        
        # Nettoyer et normaliser les emails
        if 'Email' in df_clean.columns:
            df_clean['Email'] = df_clean['Email'].astype(str).str.strip().str.lower()
            df_clean['Email'] = df_clean['Email'].replace(['nan', 'none', ''], np.nan)
            
            # V√©rifier s'il y a des doublons
            emails_avant = len(df_clean)
            emails_uniques = df_clean['Email'].nunique()
            doublons = emails_avant - emails_uniques
            
            if doublons > 0:
                # Strat√©gies de regroupement pour les donn√©es 2025
                agg_dict = {}
                
                # Fonctions d'agr√©gation
                def first_non_null(x):
                    return x.dropna().iloc[0] if len(x.dropna()) > 0 else np.nan
                
                def concat_unique(x):
                    unique_vals = x.dropna().astype(str).unique()
                    unique_vals = unique_vals[unique_vals != 'nan']
                    return ' | '.join(unique_vals) if len(unique_vals) > 0 else np.nan
                
                def latest_date(x):
                    return x.dropna().max() if len(x.dropna()) > 0 else np.nan
                
                # Colonnes texte simples : prendre la premi√®re valeur
                colonnes_simples = ['Full Name', 'Phone', 'Mobile', 'Profession', 'Contact Owner']
                for col in colonnes_simples:
                    if col in df_clean.columns:
                        agg_dict[col] = first_non_null
                
                # Traitement sp√©cial pour Produit avec normalisation
                if 'Produit' in df_clean.columns:
                    def first_non_null_normalized_produit(x):
                        x_clean = x.dropna()
                        if len(x_clean) == 0:
                            return np.nan
                        # Normaliser avant de prendre la premi√®re valeur
                        x_str = x_clean.astype(str).str.strip()
                        x_str = x_str.str.replace(r'\bimmo\b', 'Immo', regex=True, case=False)
                        x_str = x_str.str.replace(r'\bSCPIFI\b', 'SCPI', regex=True, case=False)
                        x_str = x_str.str.replace(r'\bperinsa\b', 'PERINSA', regex=True, case=False)
                        x_str = x_str.str.replace(r'\b(AVIESA|AVSA|AVPERENYS)\b', 'AVIE', regex=True, case=False)
                        return x_str.iloc[0]
                    agg_dict['Produit'] = first_non_null_normalized_produit
                
                # Colonnes √† concat√©ner : garder toutes les valeurs uniques avec normalisation
                if 'Opportunit√© Name' in df_clean.columns:
                    def concat_unique_normalized(x):
                        unique_vals = x.dropna().astype(str)
                        # Normaliser avant de concat√©ner
                        unique_vals = unique_vals.str.replace(r'\bimmo\b', 'Immo', regex=True, case=False)
                        unique_vals = unique_vals.str.replace(r'\bSCPIFI\b', 'SCPI', regex=True, case=False)
                        unique_vals = unique_vals.str.replace(r'\bperinsa\b', 'PERINSA', regex=True, case=False)
                        unique_vals = unique_vals.str.replace(r'\b(AVIESA|AVSA|AVPERENYS)\b', 'AVIE', regex=True, case=False)
                        unique_vals = unique_vals.unique()
                        unique_vals = unique_vals[unique_vals != 'nan']
                        return ' | '.join(unique_vals) if len(unique_vals) > 0 else np.nan
                    agg_dict['Opportunit√© Name'] = concat_unique_normalized
                
                if 'Stage' in df_clean.columns:
                    # Pour le stage, prendre le plus avanc√© (derni√®re valeur non nulle)
                    agg_dict['Stage'] = lambda x: x.dropna().iloc[-1] if len(x.dropna()) > 0 else np.nan
                
                # Colonnes de dates : prendre la plus r√©cente
                colonnes_dates = ['Date versement initial', 'Date validation 570', 'Date de passage comit√©']
                for col in colonnes_dates:
                    if col in df_clean.columns:
                        agg_dict[col] = latest_date
                
                # Colonnes financi√®res : sommer
                def safe_sum_financier(x):
                    from utils.data_processing_debug import safe_to_numeric_debug
                    x_numeric = safe_to_numeric_debug(x)
                    return x_numeric.sum() if not x_numeric.isna().all() else 0
                
                colonnes_financieres = ['Premier versement', 'Apport net']
                for col in colonnes_financieres:
                    if col in df_clean.columns:
                        agg_dict[col] = safe_sum_financier
                
                # Effectuer le regroupement
                try:
                    df_clean = df_clean.groupby('Email').agg(agg_dict).reset_index()
                except Exception as e:
                    # En cas d'erreur, retourner les donn√©es sans regroupement
                    pass
        
        # Nettoyage final des colonnes texte
        colonnes_texte = ['Full Name', 'Phone', 'Mobile', 'Profession', 'Contact Owner', 'Opportunit√© Name', 'Stage', 'Produit']
        for col in colonnes_texte:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].astype(str).str.strip()
                df_clean[col] = df_clean[col].replace(['nan', 'None', ''], np.nan)
        
        # Normalisation sp√©cialis√©e pour les produits et termes m√©tier
        if 'Produit' in df_clean.columns:
            # Normaliser les variantes de produits
            df_clean['Produit'] = df_clean['Produit'].str.replace(
                r'\bimmo\b', 'Immo', regex=True, case=False
            )
            df_clean['Produit'] = df_clean['Produit'].str.replace(
                r'\bSCPIFI\b', 'SCPI', regex=True, case=False
            )
            df_clean['Produit'] = df_clean['Produit'].str.replace(
                r'\bperinsa\b', 'PERINSA', regex=True, case=False
            )
            # Normaliser les variantes AVIE
            df_clean['Produit'] = df_clean['Produit'].str.replace(
                r'\b(AVIESA|AVSA|AVPERENYS)\b', 'AVIE', regex=True, case=False
            )
        
        # Normaliser aussi dans Opportunit√© Name si elle existe
        if 'Opportunit√© Name' in df_clean.columns:
            df_clean['Opportunit√© Name'] = df_clean['Opportunit√© Name'].str.replace(
                r'\bimmo\b', 'Immo', regex=True, case=False
            )
            df_clean['Opportunit√© Name'] = df_clean['Opportunit√© Name'].str.replace(
                r'\bSCPIFI\b', 'SCPI', regex=True, case=False
            )
            df_clean['Opportunit√© Name'] = df_clean['Opportunit√© Name'].str.replace(
                r'\bperinsa\b', 'PERINSA', regex=True, case=False
            )
            # Normaliser les variantes AVIE
            df_clean['Opportunit√© Name'] = df_clean['Opportunit√© Name'].str.replace(
                r'\b(AVIESA|AVSA|AVPERENYS)\b', 'AVIE', regex=True, case=False
            )
        
        return df_clean
    
    def analyser_pipeline_stages(self, df):
        """Analyse de la r√©partition par stage du pipeline"""
        st.subheader("üìä R√©partition par Stage")
        
        if 'Stage' not in df.columns:
            st.warning("‚ö†Ô∏è Colonne 'Stage' non trouv√©e")
            return
        
        # Compter les stages
        stage_counts = df['Stage'].value_counts()
        
        if not stage_counts.empty:
            # Graphique en barres
            import plotly.express as px
            fig = px.bar(
                x=stage_counts.index,
                y=stage_counts.values,
                title="Distribution des Contacts par Stage",
                labels={'x': 'Stage', 'y': 'Nombre de Contacts'},
                text=stage_counts.values
            )
            fig.update_traces(textposition='outside')
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau d√©taill√©
            stage_df = pd.DataFrame({
                'Stage': stage_counts.index,
                'Nombre': stage_counts.values,
                'Pourcentage': (stage_counts.values / len(df) * 100).round(1)
            })
            st.dataframe(stage_df, use_container_width=True)
    
    def analyser_par_contact_owner(self, df):
        """Analyse par propri√©taire de contact"""
        st.subheader("üë®‚Äçüíº Performance par Contact Owner")
        
        if 'Contact Owner' not in df.columns:
            st.warning("‚ö†Ô∏è Colonne 'Contact Owner' non trouv√©e")
            return
        
        # Analyse par contact owner
        owner_stats = df['Contact Owner'].value_counts()
        
        if not owner_stats.empty:
            # Top 10 contact owners
            top_owners = owner_stats.head(10)
            
            import plotly.express as px
            fig = px.bar(
                x=top_owners.values,
                y=top_owners.index,
                orientation='h',
                title="Top 10 Contact Owners",
                labels={'x': 'Nombre de Contacts', 'y': 'Contact Owner'},
                text=top_owners.values
            )
            fig.update_traces(textposition='outside')
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau complet
            owner_df = pd.DataFrame({
                'Contact Owner': owner_stats.index,
                'Nombre de Contacts': owner_stats.values,
                'Part (%)': (owner_stats.values / len(df) * 100).round(1)
            })
            st.dataframe(owner_df, use_container_width=True)
    
    def analyser_par_produit(self, df):
        """Analyse par produit"""
        st.subheader("üì¶ R√©partition par Produit")
        
        if 'Produit' not in df.columns:
            st.warning("‚ö†Ô∏è Colonne 'Produit' non trouv√©e")
            return
        
        # Compter les produits
        produit_counts = df['Produit'].value_counts()
        
        if not produit_counts.empty:
            # Graphique en secteurs
            import plotly.express as px
            fig = px.pie(
                values=produit_counts.values,
                names=produit_counts.index,
                title="R√©partition des Clients par Produit"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Graphique en barres
            fig_bar = px.bar(
                x=produit_counts.index,
                y=produit_counts.values,
                title="Distribution des Produits",
                labels={'x': 'Produit', 'y': 'Nombre de Clients'},
                text=produit_counts.values
            )
            fig_bar.update_traces(textposition='outside')
            st.plotly_chart(fig_bar, use_container_width=True)
            
            # Tableau d√©taill√© avec croisement Stage si disponible
            produit_df = pd.DataFrame({
                'Produit': produit_counts.index,
                'Nombre de Clients': produit_counts.values,
                'Pourcentage': (produit_counts.values / len(df) * 100).round(1)
            })
            st.dataframe(produit_df, use_container_width=True)
            
            # Croisement Produit x Stage si disponible
            if 'Stage' in df.columns:
                st.subheader("üìä Croisement Produit √ó Stage")
                crosstab_produit_stage = pd.crosstab(df['Produit'], df['Stage'], margins=True)
                st.dataframe(crosstab_produit_stage, use_container_width=True)
    
    def analyser_financier_2025(self, df):
        """Analyse des donn√©es financi√®res"""
        st.subheader("üí∞ Analyse Financi√®re")
        
        # Analyser Premier versement
        if 'Premier versement' in df.columns:
            st.subheader("üí∏ Premiers Versements")
            
            from utils.data_processing_debug import safe_to_numeric_debug
            premiers_versements = safe_to_numeric_debug(df['Premier versement'])
            
            if not premiers_versements.isna().all():
                # M√©triques
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    total = premiers_versements.sum()
                    st.metric("üí∞ Total", f"{total:,.0f}‚Ç¨")
                with col2:
                    moyenne = premiers_versements.mean()
                    st.metric("üìä Moyenne", f"{moyenne:,.0f}‚Ç¨")
                with col3:
                    mediane = premiers_versements.median()
                    st.metric("üìà M√©diane", f"{mediane:,.0f}‚Ç¨")
                with col4:
                    avec_versement = (premiers_versements > 0).sum()
                    st.metric("üë• Avec Versement", f"{avec_versement:,}")
                
                # Distribution
                import plotly.express as px
                versements_non_null = premiers_versements[premiers_versements > 0]
                if not versements_non_null.empty:
                    fig = px.histogram(
                        versements_non_null,
                        title="Distribution des Premiers Versements",
                        labels={'value': 'Montant (‚Ç¨)', 'count': 'Nombre de Clients'},
                        nbins=20
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # Analyser Apport net
        if 'Apport net' in df.columns:
            st.subheader("üè¶ Apports Nets")
            
            apports_nets = safe_to_numeric_debug(df['Apport net'])
            
            if not apports_nets.isna().all():
                # M√©triques
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    total_apport = apports_nets.sum()
                    st.metric("üí∞ Total Apports", f"{total_apport:,.0f}‚Ç¨")
                with col2:
                    moyenne_apport = apports_nets.mean()
                    st.metric("üìä Moyenne", f"{moyenne_apport:,.0f}‚Ç¨")
                with col3:
                    mediane_apport = apports_nets.median()
                    st.metric("üìà M√©diane", f"{mediane_apport:,.0f}‚Ç¨")
                with col4:
                    avec_apport = (apports_nets > 0).sum()
                    st.metric("üë• Avec Apport", f"{avec_apport:,}")
                
                # Distribution
                apports_non_null = apports_nets[apports_nets > 0]
                if not apports_non_null.empty:
                    fig = px.histogram(
                        apports_non_null,
                        title="Distribution des Apports Nets",
                        labels={'value': 'Montant (‚Ç¨)', 'count': 'Nombre de Clients'},
                        nbins=20
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        # Analyse crois√©e si les deux colonnes existent
        if 'Premier versement' in df.columns and 'Apport net' in df.columns:
            st.subheader("üîÑ Relation Premiers Versements vs Apports Nets")
            
            versements_clean = safe_to_numeric_debug(df['Premier versement'])
            apports_clean = safe_to_numeric_debug(df['Apport net'])
            
            # Cr√©er un DataFrame pour l'analyse crois√©e
            df_financier = pd.DataFrame({
                'Premier versement': versements_clean,
                'Apport net': apports_clean
            }).dropna()
            
            if not df_financier.empty:
                fig = px.scatter(
                    df_financier,
                    x='Premier versement',
                    y='Apport net',
                    title="Relation entre Premiers Versements et Apports Nets",
                    labels={'Premier versement': 'Premier Versement (‚Ç¨)', 'Apport net': 'Apport Net (‚Ç¨)'}
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Corr√©lation
                if len(df_financier) > 1:
                    correlation = df_financier.corr().iloc[0, 1]
                    st.metric("üìä Corr√©lation", f"{correlation:.3f}")
    
    def analyser_professions(self, df):
        """Analyse des professions"""
        st.subheader("üíº R√©partition par Profession")
        
        if 'Profession' not in df.columns:
            st.warning("‚ö†Ô∏è Colonne 'Profession' non trouv√©e")
            return
        
        # Compter les professions
        prof_counts = df['Profession'].value_counts().head(15)
        
        if not prof_counts.empty:
            import plotly.express as px
            fig = px.pie(
                values=prof_counts.values,
                names=prof_counts.index,
                title="Top 15 Professions"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau
            prof_df = pd.DataFrame({
                'Profession': prof_counts.index,
                'Nombre': prof_counts.values,
                'Pourcentage': (prof_counts.values / len(df) * 100).round(1)
            })
            st.dataframe(prof_df, use_container_width=True)
    
    def analyser_suivi_temporel_2025(self, df):
        """Analyse temporelle des dates"""
        st.subheader("üìÖ Suivi Temporel")
        
        # Analyser les colonnes de date disponibles
        date_columns = ['Date versement initial', 'Date validation 570', 'Date de passage comit√©']
        
        for col in date_columns:
            if col in df.columns:
                st.subheader(f"üìä {col}")
                
                # Convertir en datetime
                try:
                    from utils.data_processing_debug import safe_to_datetime_debug
                    dates = safe_to_datetime_debug(df[col])
                    dates_valides = dates.dropna()
                    
                    if not dates_valides.empty:
                        # √âvolution mensuelle
                        monthly_counts = dates_valides.dt.to_period('M').value_counts().sort_index()
                        
                        if not monthly_counts.empty:
                            import plotly.express as px
                            fig = px.line(
                                x=monthly_counts.index.astype(str),
                                y=monthly_counts.values,
                                title=f"√âvolution mensuelle - {col}",
                                labels={'x': 'Mois', 'y': 'Nombre'},
                                markers=True
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        st.metric(f"üìä {col} - Donn√©es valides", f"{len(dates_valides):,}")
                    else:
                        st.warning(f"‚ö†Ô∏è Aucune date valide trouv√©e pour {col}")
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'analyse de {col}: {str(e)}")
    
    def analyser_opportunites(self, df):
        """Analyse des montants moyens de souscription hors Immo"""
        st.subheader("üí∞ Montants Moyens de Souscription (hors Immo)")
        
        # V√©rifier les colonnes n√©cessaires
        colonnes_requises = ['Produit', 'Premier versement']
        colonnes_manquantes = [col for col in colonnes_requises if col not in df.columns]
        
        if colonnes_manquantes:
            st.warning(f"‚ö†Ô∏è Colonnes manquantes : {', '.join(colonnes_manquantes)}")
            return
        
        # Filtrer pour exclure les produits Immo
        df_hors_immo = df[~df['Produit'].str.contains('Immo', case=False, na=False)].copy()
        
        if df_hors_immo.empty:
            st.warning("‚ö†Ô∏è Aucune donn√©e trouv√©e pour les produits hors Immo")
            return
        
        st.info(f"üìä Analyse bas√©e sur {len(df_hors_immo):,} clients avec produits hors Immo")
        
        # Convertir les montants en num√©rique
        from utils.data_processing_debug import safe_to_numeric_debug
        df_hors_immo['premier_versement_num'] = safe_to_numeric_debug(df_hors_immo['Premier versement'])
        
        # Filtrer les montants valides (> 0)
        df_valide = df_hors_immo[
            (df_hors_immo['premier_versement_num'] > 0) & 
            (df_hors_immo['premier_versement_num'].notna())
        ].copy()
        
        if df_valide.empty:
            st.warning("‚ö†Ô∏è Aucun montant de premier versement valide trouv√©")
            return
        
        # Calculer les statistiques par produit
        stats_par_produit = df_valide.groupby('Produit')['premier_versement_num'].agg([
            'count', 'mean', 'median', 'std', 'min', 'max'
        ]).round(0)
        
        stats_par_produit.columns = ['Nb Clients', 'Moyenne', 'M√©diane', '√âcart-type', 'Min', 'Max']
        stats_par_produit = stats_par_produit.sort_values('Moyenne', ascending=False)
        
        # M√©triques globales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_clients = len(df_valide)
            st.metric("üë• Clients avec montant", f"{total_clients:,}")
        with col2:
            moyenne_globale = df_valide['premier_versement_num'].mean()
            st.metric("üí∞ Moyenne globale", f"{moyenne_globale:,.0f}‚Ç¨")
        with col3:
            mediane_globale = df_valide['premier_versement_num'].median()
            st.metric("üìä M√©diane globale", f"{mediane_globale:,.0f}‚Ç¨")
        with col4:
            nb_produits = stats_par_produit.shape[0]
            st.metric("üì¶ Produits analys√©s", f"{nb_produits}")
        
        # Graphique des montants moyens par produit
        import plotly.express as px
        fig = px.bar(
            stats_par_produit.reset_index(),
            x='Produit',
            y='Moyenne',
            title="Montants Moyens de Premier Versement par Produit (hors Immo)",
            labels={'Moyenne': 'Montant Moyen (‚Ç¨)', 'Produit': 'Produit'},
            text='Moyenne'
        )
        fig.update_traces(texttemplate='%{text:,.0f}‚Ç¨', textposition='outside')
        fig.update_layout(xaxis_tickangle=45, height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # Graphique en bo√Ætes pour voir les distributions
        fig_box = px.box(
            df_valide,
            x='Produit',
            y='premier_versement_num',
            title="Distribution des Montants par Produit (hors Immo)",
            labels={'premier_versement_num': 'Premier Versement (‚Ç¨)', 'Produit': 'Produit'}
        )
        fig_box.update_layout(xaxis_tickangle=45, height=600)
        st.plotly_chart(fig_box, use_container_width=True)
        
        # Tableau d√©taill√©
        st.subheader("üìä Statistiques D√©taill√©es par Produit")
        
        # Formater le tableau pour l'affichage
        stats_display = stats_par_produit.copy()
        for col in ['Moyenne', 'M√©diane', '√âcart-type', 'Min', 'Max']:
            stats_display[col] = stats_display[col].apply(lambda x: f"{x:,.0f}‚Ç¨" if pd.notna(x) else "N/A")
        
        st.dataframe(stats_display, use_container_width=True)
        
        # Analyse compl√©mentaire avec Apport net si disponible
        if 'Apport net' in df_valide.columns:
            st.subheader("üè¶ Analyse Compl√©mentaire - Apports Nets")
            
            df_valide['apport_net_num'] = safe_to_numeric_debug(df_valide['Apport net'])
            df_apports = df_valide[
                (df_valide['apport_net_num'] > 0) & 
                (df_valide['apport_net_num'].notna())
            ].copy()
            
            if not df_apports.empty:
                # Statistiques apports nets par produit
                stats_apports = df_apports.groupby('Produit')['apport_net_num'].agg([
                    'count', 'mean', 'median'
                ]).round(0)
                stats_apports.columns = ['Nb Clients', 'Apport Moyen', 'Apport M√©diane']
                
                # Graphique apports nets
                fig_apport = px.bar(
                    stats_apports.reset_index(),
                    x='Produit',
                    y='Apport Moyen',
                    title="Apports Nets Moyens par Produit (hors Immo)",
                    text='Apport Moyen'
                )
                fig_apport.update_traces(texttemplate='%{text:,.0f}‚Ç¨', textposition='outside')
                fig_apport.update_layout(xaxis_tickangle=45)
                st.plotly_chart(fig_apport, use_container_width=True)
        
        # Export des statistiques
        stats_csv = stats_par_produit.to_csv().encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger statistiques par produit (CSV)",
            data=stats_csv,
            file_name=f"montants_moyens_hors_immo_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
    
    def safe_get_numeric(self, row, column_name):
        """R√©cup√®re une valeur num√©rique d'une ligne en g√©rant les erreurs"""
        value = row.get(column_name, 0)
        if pd.isna(value) or value == '' or value == 'nan':
            return 0
        try:
            return float(value)
        except (ValueError, TypeError):
            return 0
    
    def extraire_type_produit(self, produit_complet):
        """
        Extrait le type de produit de base √† partir d'une cha√Æne compl√®te.
        Exemples:
        - '152128-Part-PERINSA-n¬∞1' -> 'PERINSA'
        - 'SCPI-n¬∞2' -> 'SCPI'  
        - 'AVIE' -> 'AVIE'
        - 'Immo' -> 'IMMO'
        """
        if not produit_complet or pd.isna(produit_complet):
            return None
            
        produit = str(produit_complet).strip().upper()
        
        # Dictionnaire de normalisation des produits (comme d√©j√† d√©fini ailleurs)
        normalisation_produits = {
            # Immobilier
            'IMMO': 'IMMO',
            'IMMOBILIER': 'IMMO',
            
            # SCPI/SCPIFI
            'SCPI': 'SCPI',
            'SCPIFI': 'SCPI',
            
            # PERINSA/PERINSA
            'PERINSA': 'PERINSA',
            'PERINSAV': 'PERINSA',
            
            # AVIE et variantes
            'AVIE': 'AVIE',
            'AVIESA': 'AVIE',
            'AVSA': 'AVIE', 
            'AVPERENYS': 'AVIE',
            
            # Autres produits courants
            'PER': 'PER',
            'ASSURANCE VIE': 'AVIE',
            'AV': 'AVIE'
        }
        
        # Chercher des motifs connus dans la cha√Æne
        for motif, type_normalise in normalisation_produits.items():
            if motif in produit:
                return type_normalise
        
        # Si aucun motif connu, essayer d'extraire le mot principal
        # Supprimer les pr√©fixes num√©riques, les tirets, les 'n¬∞', etc.
        import re
        # Pattern pour extraire le type de produit principal
        patterns = [
            r'.*?-([A-Z]+)-.*',  # 152128-Part-PERINSA-n¬∞1 -> PERINSA
            r'([A-Z]+)-N¬∞\d+',    # SCPI-n¬∞2 -> SCPI
            r'([A-Z]+)\s*N¬∞\d+',  # SCPI n¬∞2 -> SCPI
            r'^([A-Z]+)',        # Premier mot en majuscules
        ]
        
        for pattern in patterns:
            match = re.match(pattern, produit)
            if match:
                type_extrait = match.group(1).strip()
                # V√©rifier si c'est un type connu
                if type_extrait in normalisation_produits:
                    return normalisation_produits[type_extrait]
                else:
                    return type_extrait
        
        # Si rien ne fonctionne, retourner le produit nettoy√©
        # Supprimer les chiffres, tirets et caract√®res sp√©ciaux du d√©but/fin
        produit_nettoye = re.sub(r'^[\d\-\s]+', '', produit)  # Supprimer chiffres/tirets du d√©but
        produit_nettoye = re.sub(r'[\-\s]+N¬∞.*$', '', produit_nettoye)  # Supprimer -n¬∞X de la fin
        produit_nettoye = produit_nettoye.strip()
        
        return produit_nettoye if produit_nettoye else None
    
    def analyser_saisonnalite_ventes(self, df):
        """Analyse de la saisonnalit√© des ventes par produit par trimestre et nouveaux clients par an"""
        import plotly.express as px
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import pandas as pd
        from datetime import datetime
        
        st.subheader("üìà Analyse de Saisonnalit√© des Ventes")
        st.info("üìä Analyse de l'activit√© saisonni√®re par produit par trimestre et acquisition de nouveaux clients par ann√©e")
        
        # V√©rifier les colonnes n√©cessaires
        colonnes_requises = ['Date versement initial', 'Produit', 'Premier versement']
        colonnes_manquantes = [col for col in colonnes_requises if col not in df.columns]
        
        if colonnes_manquantes:
            st.error(f"‚ùå Colonnes manquantes : {', '.join(colonnes_manquantes)}")
            st.info("üí° Cette analyse n√©cessite : Date versement initial, Produit, Premier versement")
            return
        
        # Pr√©paration des donn√©es
        df_work = df.copy()
        
        # Nettoyer et convertir la date
        df_work['Date_Clean'] = pd.to_datetime(df_work['Date versement initial'], errors='coerce')
        df_work = df_work.dropna(subset=['Date_Clean'])
        
        if len(df_work) == 0:
            st.warning("‚ö†Ô∏è Aucune date valide trouv√©e")
            return
        
        # Nettoyer les montants
        df_work['Montant_Clean'] = pd.to_numeric(
            df_work['Premier versement'].astype(str).str.replace(r'[^\d.]', '', regex=True),
            errors='coerce'
        ).fillna(0)
        
        # Nettoyer les produits
        df_work['Produit_Clean'] = df_work['Produit'].str.strip().str.upper()
        
        # Ajouter les dimensions temporelles
        df_work['Annee'] = df_work['Date_Clean'].dt.year
        df_work['Trimestre'] = df_work['Date_Clean'].dt.quarter
        df_work['Trimestre_Label'] = 'T' + df_work['Trimestre'].astype(str) + ' ' + df_work['Annee'].astype(str)
        df_work['Annee_Trimestre'] = df_work['Annee'].astype(str) + '-Q' + df_work['Trimestre'].astype(str)
        
        # M√©triques g√©n√©rales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total ventes", f"{len(df_work):,}")
        with col2:
            st.metric("üìÖ P√©riode", f"{df_work['Annee'].min()}-{df_work['Annee'].max()}")
        with col3:
            st.metric("üè∑Ô∏è Produits uniques", f"{df_work['Produit_Clean'].nunique()}")
        with col4:
            ca_total = df_work['Montant_Clean'].sum()
            st.metric("üí∞ CA Total", f"{ca_total:,.0f}‚Ç¨")
        
        # Section 1: Saisonnalit√© par produit par trimestre
        st.subheader("üîÑ Saisonnalit√© par Produit et Trimestre")
        
        # Top produits pour l'analyse
        top_produits = df_work['Produit_Clean'].value_counts().head(10).index.tolist()
        
        # Filtres
        col1, col2 = st.columns(2)
        with col1:
            produits_selectionnes = st.multiselect(
                "S√©lectionner les produits √† analyser",
                options=top_produits,
                default=top_produits[:5] if len(top_produits) >= 5 else top_produits,
                key="produits_saisonnalite"
            )
        
        with col2:
            annees_disponibles = sorted(df_work['Annee'].unique())
            annees_selectionnees = st.multiselect(
                "S√©lectionner les ann√©es",
                options=annees_disponibles,
                default=annees_disponibles,
                key="annees_saisonnalite"
            )
        
        if produits_selectionnes and annees_selectionnees:
            # Filtrer les donn√©es
            df_filtre = df_work[
                (df_work['Produit_Clean'].isin(produits_selectionnes)) &
                (df_work['Annee'].isin(annees_selectionnees))
            ]
            
            # Agr√©gation par produit et trimestre
            saisonnalite = df_filtre.groupby(['Produit_Clean', 'Trimestre', 'Annee']).agg({
                'Montant_Clean': ['sum', 'count', 'mean'],
                'Date_Clean': 'count'
            }).round(0)
            
            saisonnalite.columns = ['CA', 'Nb_Ventes', 'Panier_Moyen', 'Volume']
            saisonnalite = saisonnalite.reset_index()
            
            # Graphiques de saisonnalit√©
            tab1, tab2, tab3 = st.tabs(["üìä Volume par Trimestre", "üí∞ CA par Trimestre", "üìà √âvolution Temporelle"])
            
            with tab1:
                # Heatmap volume par produit/trimestre
                pivot_volume = df_filtre.groupby(['Produit_Clean', 'Trimestre']).size().reset_index(name='Volume')
                pivot_volume = pivot_volume.pivot(index='Produit_Clean', columns='Trimestre', values='Volume').fillna(0)
                
                fig = px.imshow(
                    pivot_volume.values,
                    labels=dict(x="Trimestre", y="Produit", color="Volume"),
                    x=['T1', 'T2', 'T3', 'T4'],
                    y=pivot_volume.index.tolist(),
                    title="üî• Heatmap Volume des Ventes par Produit et Trimestre",
                    aspect="auto"
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with tab2:
                # CA par trimestre et produit
                ca_trimestre = df_filtre.groupby(['Trimestre', 'Produit_Clean'])['Montant_Clean'].sum().reset_index()
                
                fig = px.bar(
                    ca_trimestre,
                    x='Trimestre',
                    y='Montant_Clean',
                    color='Produit_Clean',
                    title="üí∞ Chiffre d'Affaires par Trimestre et Produit",
                    labels={'Montant_Clean': 'CA (‚Ç¨)', 'Trimestre': 'Trimestre'}
                )
                fig.update_layout(xaxis=dict(tickmode='array', tickvals=[1,2,3,4], ticktext=['T1', 'T2', 'T3', 'T4']))
                st.plotly_chart(fig, use_container_width=True)
            
            with tab3:
                # √âvolution temporelle par produit
                evolution = df_filtre.groupby(['Annee_Trimestre', 'Produit_Clean']).agg({
                    'Montant_Clean': 'sum',
                    'Date_Clean': 'count'
                }).reset_index()
                
                # Graphique en lignes pour chaque produit
                for produit in produits_selectionnes[:3]:  # Limiter √† 3 produits pour la lisibilit√©
                    data_produit = evolution[evolution['Produit_Clean'] == produit]
                    if not data_produit.empty:
                        fig = px.line(
                            data_produit,
                            x='Annee_Trimestre',
                            y='Montant_Clean',
                            title=f"üìà √âvolution {produit}",
                            markers=True
                        )
                        fig.update_layout(xaxis_title="P√©riode", yaxis_title="CA (‚Ç¨)")
                        st.plotly_chart(fig, use_container_width=True)
        
        # Section 2: Acquisition de nouveaux clients par ann√©e
        st.subheader("üë• Acquisition de Nouveaux Clients par Ann√©e")
        
        if 'Email' in df_work.columns:
            # Identifier les nouveaux clients par ann√©e (premi√®re souscription)
            premiers_clients = df_work.groupby('Email')['Date_Clean'].min().reset_index()
            premiers_clients['Annee_Acquisition'] = premiers_clients['Date_Clean'].dt.year
            
            # Compter les nouveaux clients par ann√©e
            nouveaux_clients_par_annee = premiers_clients['Annee_Acquisition'].value_counts().sort_index()
            
            # M√©triques nouveaux clients
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üë• Total nouveaux clients", f"{len(premiers_clients):,}")
            with col2:
                if len(nouveaux_clients_par_annee) > 1:
                    croissance = ((nouveaux_clients_par_annee.iloc[-1] / nouveaux_clients_par_annee.iloc[-2]) - 1) * 100
                    st.metric("üìà Croissance annuelle", f"{croissance:+.1f}%")
                else:
                    st.metric("üìà Croissance annuelle", "N/A")
            with col3:
                moyenne_annuelle = nouveaux_clients_par_annee.mean()
                st.metric("üìä Moyenne annuelle", f"{moyenne_annuelle:.0f}")
            with col4:
                annee_peak = nouveaux_clients_par_annee.idxmax()
                st.metric("üéØ Meilleure ann√©e", f"{annee_peak}")
            
            # Graphiques nouveaux clients
            col1, col2 = st.columns(2)
            
            with col1:
                # √âvolution des nouveaux clients par ann√©e
                fig = px.bar(
                    x=nouveaux_clients_par_annee.index,
                    y=nouveaux_clients_par_annee.values,
                    title="üë• Nouveaux Clients par Ann√©e",
                    labels={'x': 'Ann√©e', 'y': 'Nombre de nouveaux clients'},
                    text=nouveaux_clients_par_annee.values
                )
                fig.update_traces(textposition='outside')
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # R√©partition trimestrielle des acquisitions
                premiers_clients['Trimestre'] = premiers_clients['Date_Clean'].dt.quarter
                acquisition_trimestre = premiers_clients['Trimestre'].value_counts().sort_index()
                
                fig = px.pie(
                    values=acquisition_trimestre.values,
                    names=[f'T{i}' for i in acquisition_trimestre.index],
                    title="üîÑ Saisonnalit√© Acquisition Clients",
                    hole=0.4
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Analyse d√©taill√©e par ann√©e et produit
            st.subheader("üîç Analyse Crois√©e: Nouveaux Clients et Produits")
            
            # Croiser donn√©es clients avec produits pr√©f√©r√©s
            clients_produits = df_work.merge(
                premiers_clients[['Email', 'Annee_Acquisition']],
                on='Email'
            )
            
            # Produits pr√©f√©r√©s des nouveaux clients par ann√©e
            produits_nouveaux = clients_produits.groupby(['Annee_Acquisition', 'Produit_Clean']).size().reset_index(name='Volume')
            
            # Top produits par ann√©e pour nouveaux clients
            for annee in sorted(clients_produits['Annee_Acquisition'].unique())[-3:]:  # 3 derni√®res ann√©es
                data_annee = produits_nouveaux[produits_nouveaux['Annee_Acquisition'] == annee]
                top_produits_annee = data_annee.nlargest(5, 'Volume')
                
                if not top_produits_annee.empty:
                    with st.expander(f"üìä Top Produits Nouveaux Clients {annee}"):
                        fig = px.bar(
                            top_produits_annee,
                            x='Volume',
                            y='Produit_Clean',
                            orientation='h',
                            title=f"Top 5 Produits - Nouveaux Clients {annee}",
                            text='Volume'
                        )
                        fig.update_traces(textposition='outside')
                        st.plotly_chart(fig, use_container_width=True)
        
        else:
            st.warning("‚ö†Ô∏è Colonne 'Email' manquante - Impossible d'analyser l'acquisition de nouveaux clients")
        
        # Export des donn√©es d'analyse
        st.subheader("üì• Export des Analyses")
        
        # Pr√©parer les donn√©es d'export
        export_data = df_work.copy()
        
        # Ajouter des colonnes calcul√©es
        export_data['Saison'] = export_data['Trimestre'].map({
            1: 'Hiver', 2: 'Printemps', 3: '√ât√©', 4: 'Automne'
        })
        
        csv_export = export_data.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger analyse saisonnalit√© (CSV)",
            data=csv_export,
            file_name=f"analyse_saisonnalite_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
    
    def analyser_multi_equipement(self, df):
        """Analyse des clients mono-√©quip√©s vs multi-√©quip√©s bas√©e sur les types de produits distincts"""
        st.subheader("üéØ Analyse du Multi-√©quipement Client")
        st.info("üìä Cette analyse compte les **types de produits distincts** par client (ex: PERINSA-n¬∞1 et PERINSA-n¬∞2 = 1 seul type)")
        
        if 'Produit' not in df.columns:
            st.warning("‚ö†Ô∏è Colonne 'Produit' non trouv√©e")
            return
        
        # Analyser les donn√©es uniquement apr√®s regroupement par email
        if 'Email' not in df.columns:
            st.warning("‚ö†Ô∏è Colonne 'Email' non trouv√©e pour analyser les clients uniques")
            return
        
        st.info("üìä Cette analyse est bas√©e sur les clients uniques (regroup√©s par email)")
        
        # Pour analyser le multi-√©quipement, nous devons regarder les donn√©es originales
        # car apr√®s regroupement, nous n'avons plus le d√©tail des produits multiples
        # Nous allons cr√©er une analyse bas√©e sur les colonnes 'Produit' et 'Opportunit√© Name'
        
        # Analyser les produits par client
        clients_produits = {}
        
        # Si les produits sont dans 'Produit', les analyser directement
        for idx, row in df.iterrows():
            email = row.get('Email', '')
            produit = row.get('Produit', '')
            opportunite = row.get('Opportunit√© Name', '')
            
            if pd.notna(email) and email != 'nan' and email != '':
                if email not in clients_produits:
                    clients_produits[email] = {
                        'produits': set(),
                        'opportunites': set(),
                        'full_name': row.get('Full Name', ''),
                        'profession': row.get('Profession', ''),
                        'stage': row.get('Stage', ''),
                        'phone': row.get('Phone', ''),
                        'mobile': row.get('Mobile', ''),
                        'contact_owner': row.get('Contact Owner', ''),
                        'premier_versement': self.safe_get_numeric(row, 'Premier versement'),
                        'apport_net': self.safe_get_numeric(row, 'Apport net')
                    }
                
                if pd.notna(produit) and produit != 'nan' and produit != '':
                    # S√©parer les produits s'ils sont concat√©n√©s avec |
                    produits_split = str(produit).split('|') if '|' in str(produit) else [str(produit)]
                    for p in produits_split:
                        p_clean = p.strip()
                        if p_clean and p_clean != 'nan':
                            # Extraire le type de produit de base (sans les num√©ros)
                            type_produit = self.extraire_type_produit(p_clean)
                            if type_produit:
                                clients_produits[email]['produits'].add(type_produit)
                
                if pd.notna(opportunite) and opportunite != 'nan' and opportunite != '':
                    # S√©parer les opportunit√©s s'elles sont concat√©n√©es avec |
                    opp_split = str(opportunite).split('|') if '|' in str(opportunite) else [str(opportunite)]
                    for o in opp_split:
                        o_clean = o.strip()
                        if o_clean and o_clean != 'nan':
                            # Extraire le type de produit de base de l'opportunit√©
                            type_produit = self.extraire_type_produit(o_clean)
                            if type_produit:
                                clients_produits[email]['opportunites'].add(type_produit)
        
        # Cr√©er un DataFrame d'analyse
        analyse_data = []
        for email, data in clients_produits.items():
            nb_produits = len(data['produits'])
            nb_opportunites = len(data['opportunites'])
            # Combiner produits et opportunit√©s pour avoir une vue compl√®te
            tous_produits = data['produits'].union(data['opportunites'])
            nb_total_produits = len(tous_produits)
            
            if nb_total_produits > 0:  # Ignorer les clients sans produits
                # Cr√©er un num√©ro de t√©l√©phone consolid√© (Phone ou Mobile)
                telephone = ''
                if data['phone'] and str(data['phone']) not in ['', 'nan', 'None']:
                    telephone = str(data['phone'])
                elif data['mobile'] and str(data['mobile']) not in ['', 'nan', 'None']:
                    telephone = str(data['mobile'])
                
                # Calculer le panier moyen hors Immo
                panier_moyen_hors_immo = 0
                if data['premier_versement'] and pd.notna(data['premier_versement']) and data['premier_versement'] > 0:
                    # V√©rifier si le client a des produits immobiliers
                    produits_immo = {'IMMO', 'Immobilier'}
                    produits_client = tous_produits
                    has_immo = any(p in produits_immo for p in produits_client)
                    
                    # Si le client n'a que de l'immo, panier = 0, sinon utiliser le premier versement
                    if not (has_immo and len(produits_client) == 1):
                        panier_moyen_hors_immo = data['premier_versement']
                
                # Calculer la segmentation bas√©e sur le panier moyen hors Immo
                segmentation = "PGP"  # Par d√©faut
                if panier_moyen_hors_immo >= 30000:
                    segmentation = "CPP"
                elif panier_moyen_hors_immo >= 10000:
                    segmentation = "PGP+"
                # Sinon reste "PGP" pour < 10k‚Ç¨

                analyse_data.append({
                    'Email': email,
                    'Full Name': data['full_name'],
                    'Profession': data['profession'],
                    'Stage': data['stage'],
                    'Phone': data['phone'],
                    'Mobile': data['mobile'],
                    'Telephone': telephone,
                    'Contact Owner': data['contact_owner'],
                    'Nb_Produits_Directs': nb_produits,
                    'Nb_Opportunites': nb_opportunites,
                    'Nb_Total_Produits': nb_total_produits,
                    'Produits': ' | '.join(sorted(data['produits'])),
                    'Opportunites': ' | '.join(sorted(data['opportunites'])),
                    'Tous_Produits': ' | '.join(sorted(tous_produits)),
                    'Type_Client': 'Multi-√©quip√©' if nb_total_produits > 1 else 'Mono-√©quip√©',
                    'Premier_Versement': data['premier_versement'],
                    'Apport_Net': data['apport_net'],
                    'Panier_Moyen_Hors_Immo': panier_moyen_hors_immo,
                    'Segmentation': segmentation
                })
        
        if not analyse_data:
            st.warning("‚ö†Ô∏è Aucune donn√©e de produit trouv√©e pour l'analyse")
            return
        
        df_analyse = pd.DataFrame(analyse_data)
        
        # M√©triques principales
        total_clients = len(df_analyse)
        clients_mono = len(df_analyse[df_analyse['Type_Client'] == 'Mono-√©quip√©'])
        clients_multi = len(df_analyse[df_analyse['Type_Client'] == 'Multi-√©quip√©'])
        
        st.markdown("---")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üë• Total Clients", f"{total_clients:,}")
        with col2:
            st.metric("üéØ Mono-√©quip√©s", f"{clients_mono:,}", 
                     help="Clients avec 1 seul produit")
        with col3:
            st.metric("üèÜ Multi-√©quip√©s", f"{clients_multi:,}", 
                     help="Clients avec plusieurs produits")
        with col4:
            taux_multi = (clients_multi / total_clients) * 100 if total_clients > 0 else 0
            st.metric("üìà Taux Multi-√©quip.", f"{taux_multi:.1f}%")
        
        # Explication de la logique de calcul
        with st.expander("üí° Comment fonctionne le calcul multi-√©quipement ?", expanded=False):
            st.markdown("""
            **M√©thode de calcul :**
            - ‚úÖ **Mono-√©quip√©** : Client avec un seul **type** de produit
                - Exemple : `PERINSA-n¬∞1` et `PERINSA-n¬∞2` = **1 seul type** (PERINSA) 
            - ‚úÖ **Multi-√©quip√©** : Client avec plusieurs **types** de produits
                - Exemple : `PERINSA-n¬∞1` + `SCPI-n¬∞1` = **2 types** (PERINSA + SCPI)
            
            **Normalisation des produits :**
            - `SCPIFI` ‚Üí `SCPI`
            - `AVIESA`, `AVSA`, `AVPERENYS` ‚Üí `AVIE`  
            - `IMMO`, `Immobilier` ‚Üí `IMMO`
            
            **Sources de donn√©es :**
            - Colonne `Produit` : produits directs
            - Colonne `Opportunit√© Name` : opportunit√©s commerciales
            """)
            
            # Montrer quelques exemples concrets s'il y en a
            if len(df_analyse) > 0:
                st.markdown("**Exemples concrets de votre dataset :**")
                
                # Exemples de clients mono-√©quip√©s
                mono_exemples = df_analyse[df_analyse['Type_Client'] == 'Mono-√©quip√©'].head(3)
                if not mono_exemples.empty:
                    st.markdown("**Clients mono-√©quip√©s :**")
                    for _, row in mono_exemples.iterrows():
                        st.write(f"‚Ä¢ {row['Full Name']} : {row['Tous_Produits']}")
                
                # Exemples de clients multi-√©quip√©s
                multi_exemples = df_analyse[df_analyse['Type_Client'] == 'Multi-√©quip√©'].head(3)
                if not multi_exemples.empty:
                    st.markdown("**Clients multi-√©quip√©s :**")
                    for _, row in multi_exemples.iterrows():
                        st.write(f"‚Ä¢ {row['Full Name']} : {row['Tous_Produits']} ({row['Nb_Total_Produits']} types)")
        
        # Graphiques
        import plotly.express as px
        
        # R√©partition mono vs multi
        repartition = df_analyse['Type_Client'].value_counts()
        fig_pie = px.pie(
            values=repartition.values,
            names=repartition.index,
            title="R√©partition Mono-√©quip√©s vs Multi-√©quip√©s",
            color_discrete_map={'Mono-√©quip√©': '#ff7f7f', 'Multi-√©quip√©': '#7fbf7f'}
        )
        st.plotly_chart(fig_pie, use_container_width=True)
        
        # Distribution du nombre de produits
        distribution_produits = df_analyse['Nb_Total_Produits'].value_counts().sort_index()
        fig_bar = px.bar(
            x=distribution_produits.index,
            y=distribution_produits.values,
            title="Distribution du Nombre de Produits par Client",
            labels={'x': 'Nombre de Produits', 'y': 'Nombre de Clients'},
            text=distribution_produits.values
        )
        fig_bar.update_traces(textposition='outside')
        st.plotly_chart(fig_bar, use_container_width=True)
        
        # Analyse par profession si disponible
        if 'Profession' in df_analyse.columns and df_analyse['Profession'].notna().any():
            st.subheader("üíº Multi-√©quipement par Profession")
            
            prof_analysis = df_analyse.groupby(['Profession', 'Type_Client']).size().unstack(fill_value=0)
            if not prof_analysis.empty:
                # Calculer le taux de multi-√©quipement par profession
                prof_analysis['Total'] = prof_analysis.sum(axis=1)
                prof_analysis['Taux_Multi'] = (prof_analysis.get('Multi-√©quip√©', 0) / prof_analysis['Total'] * 100).round(1)
                prof_analysis_sorted = prof_analysis.sort_values('Taux_Multi', ascending=False).head(10)
                
                fig_prof = px.bar(
                    prof_analysis_sorted.reset_index(),
                    x='Profession',
                    y='Taux_Multi',
                    title="Top 10 Professions - Taux de Multi-√©quipement",
                    labels={'Taux_Multi': 'Taux Multi-√©quipement (%)', 'Profession': 'Profession'},
                    text='Taux_Multi'
                )
                fig_prof.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
                fig_prof.update_layout(xaxis_tickangle=45)
                st.plotly_chart(fig_prof, use_container_width=True)
        
        # Analyse financi√®re si disponible
        from utils.data_processing_debug import safe_to_numeric_debug
        df_analyse['Premier_Versement_Num'] = safe_to_numeric_debug(df_analyse['Premier_Versement'])
        df_analyse['Apport_Net_Num'] = safe_to_numeric_debug(df_analyse['Apport_Net'])
        
        df_financier = df_analyse[
            (df_analyse['Premier_Versement_Num'] > 0) | 
            (df_analyse['Apport_Net_Num'] > 0)
        ].copy()
        
        if not df_financier.empty:
            st.subheader("üí∞ Impact Financier du Multi-√©quipement")
            
            # Comparaison montants moyens
            financial_comparison = df_financier.groupby('Type_Client').agg({
                'Premier_Versement_Num': ['count', 'mean', 'median'],
                'Apport_Net_Num': ['mean', 'median']
            }).round(0)
            
            col1, col2 = st.columns(2)
            
            with col1:
                if 'Premier_Versement_Num' in df_financier.columns:
                    mono_avg = df_financier[df_financier['Type_Client'] == 'Mono-√©quip√©']['Premier_Versement_Num'].mean()
                    multi_avg = df_financier[df_financier['Type_Client'] == 'Multi-√©quip√©']['Premier_Versement_Num'].mean()
                    
                    if pd.notna(mono_avg) and pd.notna(multi_avg):
                        st.metric("üí∏ Premier Versement Moyen - Mono", f"{mono_avg:,.0f}‚Ç¨")
                        st.metric("üí∏ Premier Versement Moyen - Multi", f"{multi_avg:,.0f}‚Ç¨")
                        
                        ecart = ((multi_avg - mono_avg) / mono_avg * 100) if mono_avg > 0 else 0
                        st.metric("üìä √âcart Multi vs Mono", f"{ecart:+.1f}%")
            
            with col2:
                if 'Apport_Net_Num' in df_financier.columns:
                    mono_apport = df_financier[df_financier['Type_Client'] == 'Mono-√©quip√©']['Apport_Net_Num'].mean()
                    multi_apport = df_financier[df_financier['Type_Client'] == 'Multi-√©quip√©']['Apport_Net_Num'].mean()
                    
                    if pd.notna(mono_apport) and pd.notna(multi_apport):
                        st.metric("üè¶ Apport Net Moyen - Mono", f"{mono_apport:,.0f}‚Ç¨")
                        st.metric("üè¶ Apport Net Moyen - Multi", f"{multi_apport:,.0f}‚Ç¨")
        
        # Tableaux d√©taill√©s
        st.subheader("üìä D√©tail des Clients Multi-√©quip√©s")
        
        df_multi = df_analyse[df_analyse['Type_Client'] == 'Multi-√©quip√©'].copy()
        if not df_multi.empty:
            df_multi_display = df_multi[['Full Name', 'Profession', 'Nb_Total_Produits', 'Tous_Produits', 'Stage']].copy()
            df_multi_display = df_multi_display.sort_values('Nb_Total_Produits', ascending=False)
            st.dataframe(df_multi_display, use_container_width=True)
        
        st.subheader("üìã R√©sum√© par Nombre de Produits")
        summary = df_analyse.groupby('Nb_Total_Produits').agg({
            'Email': 'count',
            'Premier_Versement_Num': 'mean',
            'Apport_Net_Num': 'mean'
        }).round(0)
        summary.columns = ['Nombre de Clients', 'Premier Versement Moyen', 'Apport Net Moyen']
        summary = summary.reset_index()
        summary.rename(columns={'Nb_Total_Produits': 'Nombre de Produits'}, inplace=True)
        
        # Formater les montants
        for col in ['Premier Versement Moyen', 'Apport Net Moyen']:
            summary[col] = summary[col].apply(lambda x: f"{x:,.0f}‚Ç¨" if pd.notna(x) and x > 0 else "N/A")
        
        st.dataframe(summary, use_container_width=True)
        
        # Export
        # Colonnes √† exporter avec les nouveaux champs demand√©s
        colonnes_export = [
            'Email', 'Full Name', 'Telephone', 'Contact Owner', 
            'Profession', 'Stage', 'Type_Client', 'Nb_Total_Produits', 
            'Tous_Produits', 'Premier_Versement', 'Apport_Net', 
            'Panier_Moyen_Hors_Immo', 'Segmentation'
        ]
        
        # V√©rifier que les colonnes existent dans le DataFrame
        colonnes_disponibles = [col for col in colonnes_export if col in df_analyse.columns]
        
        export_data = df_analyse[colonnes_disponibles].copy()
        
        # Formatter les montants pour l'export avec gestion d'erreur
        def format_montant(x):
            """Formate un montant en g√©rant les valeurs vides ou non num√©riques"""
            if pd.isna(x) or x == '' or x == 0:
                return ""
            try:
                # Essayer de convertir en float
                montant = float(x)
                if montant == 0:
                    return ""
                return f"{montant:,.0f}‚Ç¨"
            except (ValueError, TypeError):
                # Si la conversion √©choue, retourner vide
                return ""
        
        if 'Premier_Versement' in export_data.columns:
            export_data['Premier_Versement'] = export_data['Premier_Versement'].apply(format_montant)
        if 'Apport_Net' in export_data.columns:
            export_data['Apport_Net'] = export_data['Apport_Net'].apply(format_montant)
        if 'Panier_Moyen_Hors_Immo' in export_data.columns:
            export_data['Panier_Moyen_Hors_Immo'] = export_data['Panier_Moyen_Hors_Immo'].apply(format_montant)
        csv_multi = export_data.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger analyse multi-√©quipement (CSV)",
            data=csv_multi,
            file_name=f"analyse_multi_equipement_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
        
        # Aper√ßu de l'export multi-√©quipement
        with st.expander("üìÑ Aper√ßu de l'export multi-√©quipement", expanded=False):
            # Cr√©er une version avec colonnes renomm√©es pour l'aper√ßu
            export_preview = export_data.copy()
            nouvelles_colonnes = []
            if 'Telephone' in export_preview.columns and 'Contact Owner' in export_preview.columns:
                nouvelles_colonnes.append("T√©l√©phone, Contact Owner")
            if 'Panier_Moyen_Hors_Immo' in export_preview.columns and 'Segmentation' in export_preview.columns:
                nouvelles_colonnes.append("Panier Moyen Hors Immo, Segmentation (PGP/PGP+/CPP)")
            
            if nouvelles_colonnes:
                st.write(f"**‚úÖ Nouvelles colonnes ajout√©es :** {' | '.join(nouvelles_colonnes)}")
            
            colonnes_actuelles = list(export_preview.columns)
            st.write(f"**Colonnes export√©es :** {', '.join(colonnes_actuelles)}")
            st.write(f"**Nombre de clients :** {len(export_preview):,}")
            
            # Afficher les crit√®res de segmentation
            st.markdown("""
            **üìä Crit√®res de Segmentation :**
            - **PGP** : Panier moyen < 10 000‚Ç¨
            - **PGP+** : Panier moyen entre 10 000‚Ç¨ et 30 000‚Ç¨  
            - **CPP** : Panier moyen ‚â• 30 000‚Ç¨
            - *Note : Panier calcul√© hors produits immobiliers*
            """)
            
            if not export_preview.empty:
                st.dataframe(export_preview.head(5), use_container_width=True)
    
    def analyser_segmentation_immo(self, df):
        """Analyse de segmentation IMMO avec mono-√©quip√©s et 6 segments bas√©s sur activit√© et panier moyen"""
        import plotly.express as px
        import pandas as pd
        from datetime import datetime
        
        st.subheader("üè† Segmentation Compl√®te")
        st.info("üìä Segmentation avec 7 segments : IMMO mono-√©quip√© + 6 segments CPP/PGP actifs/inactifs")
        st.markdown("üí° **Les 7 segments :** IMMO mono-√©quip√©, CPP/PGP+ Actifs (>30k‚Ç¨, 10-30k‚Ç¨, <10k‚Ç¨), CPP/PGP+ Inactifs (>30k‚Ç¨, 10-30k‚Ç¨, <10k‚Ç¨)")
        
        # Identifier les clients mono-√©quip√©s IMMO uniquement
        if 'Produit' not in df.columns:
            st.warning("‚ö†Ô∏è Colonne 'Produit' non trouv√©e. Impossible d'analyser les mono-√©quip√©s IMMO.")
            return
        
        # Pr√©parer tous les clients pour la segmentation en 7 segments
        df_work = df.copy()
        
        # V√©rifier l'Email pour identifier les clients uniques
        if 'Email' not in df_work.columns:
            st.warning("‚ö†Ô∏è Colonne 'Email' non trouv√©e. Impossible d'identifier les clients uniques.")
            return
        
        # Analyser les produits de chaque client
        client_produits = df_work.groupby('Email')['Produit'].agg(['unique', 'count']).reset_index()
        client_produits.columns = ['Email', 'Liste_Produits_Uniques', 'Nb_Total_Souscriptions']
        
        # Identifier les clients qui ont UNIQUEMENT le produit "IMMO" (segment sp√©cial)
        def est_segment_immo_mono(produits_array):
            # Convertir numpy array en liste si n√©cessaire
            if hasattr(produits_array, 'tolist'):
                produits_list = produits_array.tolist()
            elif not isinstance(produits_array, list):
                produits_list = [produits_array]
            else:
                produits_list = produits_array
            
            # Nettoyer et normaliser les noms de produits
            produits_clean = [str(p).strip().upper() for p in produits_list if pd.notna(p) and str(p) != 'nan']
            
            if len(produits_clean) == 0:
                return False
            
            # V√©rifier si tous les produits contiennent "IMMO" mais pas d'autres types
            for produit in produits_clean:
                if 'IMMO' not in produit:
                    return False
                # Exclure les produits qui contiennent d'autres mots-cl√©s
                if any(autre in produit for autre in ['PER', 'SCPI', 'SCI', 'FONCIERE', 'EPARGNE']):
                    return False
            
            return True
        
        client_produits['Est_IMMO_Mono'] = client_produits['Liste_Produits_Uniques'].apply(est_segment_immo_mono)
        
        # Pr√©parer les donn√©es pour la segmentation compl√®te (tous les clients)
        df_segmentation = df_work.copy()
        
        # Nettoyer et convertir les montants
        montant_col = None
        for col in ['Premier versement', 'Premier Versement', 'Montant', 'Premier_versement']:
            if col in df_segmentation.columns:
                montant_col = col
                break
        
        if montant_col is None:
            st.warning("‚ö†Ô∏è Aucune colonne de montant trouv√©e. Utilisation d'un montant par d√©faut de 15 000‚Ç¨")
            df_segmentation['Montant_Clean'] = 15000
        else:
            # Nettoyer les montants
            df_segmentation['Montant_Clean'] = pd.to_numeric(
                df_segmentation[montant_col].astype(str).str.replace(r'[^\d.]', '', regex=True),
                errors='coerce'
            ).fillna(15000)
        
        # V√©rifier l'activit√© 2024 (par d√©faut consid√©rer tous comme actifs si pas de date)
        date_col = None
        for col in ['Date versement initial', 'Date_versement', 'Date', 'Date de souscription']:
            if col in df_segmentation.columns:
                date_col = col
                break
        
        if date_col:
            df_segmentation['Date_Clean'] = pd.to_datetime(df_segmentation[date_col], errors='coerce')
            df_segmentation['Actif_2024'] = df_segmentation['Date_Clean'].dt.year >= 2024
        else:
            st.info("‚ÑπÔ∏è Aucune colonne de date trouv√©e. Tous les clients sont consid√©r√©s comme actifs.")
            df_segmentation['Actif_2024'] = True
        
        # Calculer le panier moyen par client
        client_stats = df_segmentation.groupby('Email').agg({
            'Montant_Clean': ['mean', 'sum', 'count'],
            'Actif_2024': 'any'
        }).round(0)
        
        client_stats.columns = ['Panier_Moyen', 'Montant_Total', 'Nb_Souscriptions', 'Actif_2024']
        client_stats = client_stats.reset_index()
        
        # Ajouter l'information IMMO mono aux statistiques clients
        client_stats = client_stats.merge(
            client_produits[['Email', 'Est_IMMO_Mono']], 
            on='Email', 
            how='left'
        ).fillna(False)
        
        # D√©finir les 7 segments selon vos crit√®res
        def attribuer_segment(row):
            # Segment sp√©cial IMMO mono-√©quip√© (priorit√©)
            if row['Est_IMMO_Mono']:
                return "üè† IMMO Mono-√©quip√©"
            
            # Les 6 autres segments bas√©s sur activit√© et panier moyen
            panier_moyen = row['Panier_Moyen']
            actif = row['Actif_2024']
            
            if actif:
                if panier_moyen > 30000:
                    return "üü¢ CPP Actif (Gros potentiel >30k‚Ç¨)"
                elif panier_moyen >= 10000:
                    return "üü° PGP+ Actif (Moyen potentiel 10-30k‚Ç¨)"
                else:
                    return "üü† PGP Actif (Petit potentiel <10k‚Ç¨)"
            else:
                if panier_moyen > 30000:
                    return "üî¥ CPP Inactif (Gros potentiel >30k‚Ç¨)"
                elif panier_moyen >= 10000:
                    return "üî¥ PGP+ Inactif (Moyen potentiel 10-30k‚Ç¨)"
                else:
                    return "üî¥ PGP Inactif (Petit potentiel <10k‚Ç¨)"
        
        client_stats['Segment'] = client_stats.apply(attribuer_segment, axis=1)
        
        # Affichage des m√©triques g√©n√©rales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total clients", f"{len(client_stats):,}")
        with col2:
            immo_mono = len(client_stats[client_stats['Est_IMMO_Mono']])
            st.metric("üè† IMMO Mono-√©quip√©s", f"{immo_mono:,}")
        with col3:
            actifs = len(client_stats[client_stats['Actif_2024']])
            st.metric("‚úÖ Clients actifs 2024", f"{actifs:,}")
        with col4:
            panier_moyen_global = client_stats['Panier_Moyen'].mean()
            st.metric("üí∞ Panier moyen global", f"{panier_moyen_global:,.0f}‚Ç¨")
        
        # Visualisations de la segmentation
        col1, col2 = st.columns(2)
        
        with col1:
            # R√©partition par segments
            segment_counts = client_stats['Segment'].value_counts()
            fig_segments = px.pie(
                values=segment_counts.values,
                names=segment_counts.index,
                title="üéØ R√©partition par Segments",
                hole=0.4
            )
            st.plotly_chart(fig_segments, use_container_width=True)
        
        with col2:
            # Panier moyen par segment
            segment_stats = client_stats.groupby('Segment').agg({
                'Panier_Moyen': 'mean',
                'Email': 'count'
            }).reset_index()
            segment_stats.columns = ['Segment', 'Panier_Moyen', 'Nb_Clients']
            
            fig_panier = px.bar(
                segment_stats,
                x='Nb_Clients',
                y='Segment',
                title="üìä Nombre de clients par segment",
                orientation='h',
                text='Nb_Clients'
            )
            fig_panier.update_traces(textposition='outside')
            st.plotly_chart(fig_panier, use_container_width=True)
        
        # Tableau d√©taill√© des segments
        st.subheader("üìã D√©tail des Segments")
        segment_detail = client_stats.groupby('Segment').agg({
            'Email': 'count',
            'Panier_Moyen': ['mean', 'median', 'min', 'max'],
            'Montant_Total': 'sum',
            'Nb_Souscriptions': 'sum'
        }).round(0)
        
        # Aplatir les colonnes multi-niveaux
        segment_detail.columns = ['Nb_Clients', 'Panier_Moyen', 'Panier_Median', 'Panier_Min', 'Panier_Max', 'CA_Total', 'Souscriptions_Total']
        segment_detail = segment_detail.reset_index()
        
        # Ajouter le pourcentage
        segment_detail['Pourcentage'] = (segment_detail['Nb_Clients'] / len(client_stats) * 100).round(1)
        
        # Formater les montants
        for col in ['Panier_Moyen', 'Panier_Median', 'Panier_Min', 'Panier_Max']:
            segment_detail[col] = segment_detail[col].apply(lambda x: f"{x:,.0f}‚Ç¨")
        segment_detail['CA_Total'] = segment_detail['CA_Total'].apply(lambda x: f"{x:,.0f}‚Ç¨")
        segment_detail['Pourcentage'] = segment_detail['Pourcentage'].apply(lambda x: f"{x}%")
        
        st.dataframe(segment_detail, use_container_width=True)
        
        # Analyse d√©taill√©e pour tous les segments - Affichage direct
        st.subheader("üîç Analyse D√©taill√©e des 7 Segments")
        
        # Afficher tous les segments directement, organis√©s par cat√©gorie
        all_segments = [
            "üè† IMMO Mono-√©quip√©",
            "üü¢ CPP Actif (Gros potentiel >30k‚Ç¨)", 
            "üü° PGP+ Actif (Moyen potentiel 10-30k‚Ç¨)", 
            "üü† PGP Actif (Petit potentiel <10k‚Ç¨)",
            "üî¥ CPP Inactif (Gros potentiel >30k‚Ç¨)", 
            "üî¥ PGP+ Inactif (Moyen potentiel 10-30k‚Ç¨)", 
            "üî¥ PGP Inactif (Petit potentiel <10k‚Ç¨)"
        ]
        
        # Organis√© en colonnes pour un affichage compact
        col1, col2 = st.columns(2)
        
        segments_gauche = all_segments[:4]  # IMMO + 3 premiers
        segments_droite = all_segments[4:]  # 3 derniers
        
        with col1:
            st.markdown("### üè† IMMO & Segments Actifs")
            for segment in segments_gauche:
                if segment in client_stats['Segment'].values:
                    segment_data = client_stats[client_stats['Segment'] == segment]
                    with st.expander(f"{segment} ({len(segment_data)} clients)", expanded=False):
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("Panier moyen", f"{segment_data['Panier_Moyen'].mean():,.0f}‚Ç¨")
                        with col_b:
                            st.metric("CA total", f"{segment_data['Montant_Total'].sum():,.0f}‚Ç¨")
                        with col_c:
                            st.metric("Souscriptions", f"{segment_data['Nb_Souscriptions'].sum():.0f}")
                        
                        if "IMMO" in segment:
                            st.write("**Caract√©ristiques :** Clients ayant uniquement le produit IMMO")
                        elif "Actif" in segment:
                            st.write("**Caract√©ristiques :** Clients avec souscriptions en 2024")
                else:
                    st.info(f"Aucun client dans le segment {segment}")
        
        with col2:
            st.markdown("### üî¥ Segments Inactifs")
            for segment in segments_droite:
                if segment in client_stats['Segment'].values:
                    segment_data = client_stats[client_stats['Segment'] == segment]
                    with st.expander(f"{segment} ({len(segment_data)} clients)", expanded=False):
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("Panier moyen", f"{segment_data['Panier_Moyen'].mean():,.0f}‚Ç¨")
                        with col_b:
                            st.metric("CA total", f"{segment_data['Montant_Total'].sum():,.0f}‚Ç¨")
                        with col_c:
                            st.metric("Souscriptions", f"{segment_data['Nb_Souscriptions'].sum():.0f}")
                        
                        st.write("**Caract√©ristiques :** Clients sans souscription en 2024")
                else:
                    st.info(f"Aucun client dans le segment {segment}")
        
        # Vue d'ensemble rapide des 7 segments
        st.subheader("üìä Vue d'Ensemble Rapide")
        segment_summary = client_stats['Segment'].value_counts().reset_index()
        segment_summary.columns = ['Segment', 'Nombre_Clients']
        segment_summary['Pourcentage'] = (segment_summary['Nombre_Clients'] / len(client_stats) * 100).round(1)
        
        # Affichage en colonnes
        cols = st.columns(4)
        for i, (_, row) in enumerate(segment_summary.iterrows()):
            with cols[i % 4]:
                st.metric(
                    row['Segment'][:20] + "..." if len(row['Segment']) > 20 else row['Segment'],
                    f"{row['Nombre_Clients']} ({row['Pourcentage']}%)"
                )
        
        # Export des donn√©es segment√©es
        st.subheader("üì• Export Segmentation Compl√®te")
        
        # Enrichir les donn√©es client avec les segments
        df_export = df_segmentation.merge(
            client_stats[['Email', 'Segment', 'Panier_Moyen', 'Est_IMMO_Mono']],
            on='Email',
            how='left'
        )
        
        csv_export = df_export.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger segmentation compl√®te - 7 segments (CSV)",
            data=csv_export,
            file_name=f"segmentation_complete_7segments_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
        
        # R√©sum√© de la segmentation
        st.info(f"""
        **üìä R√©sum√© de la segmentation :**
        - **üè† IMMO Mono-√©quip√©** : {len(client_stats[client_stats['Segment'] == 'üè† IMMO Mono-√©quip√©'])} clients
        - **üü¢ Segments Actifs** : {len(client_stats[client_stats['Segment'].str.contains('Actif', na=False)])} clients  
        - **üî¥ Segments Inactifs** : {len(client_stats[client_stats['Segment'].str.contains('Inactif', na=False)])} clients
        - **üìä Total** : {len(client_stats)} clients segment√©s
        """)
    
    def generer_export_2025(self, df):
        """G√©n√©ration des exports pour l'analyse 2025"""
        st.subheader("üì§ Export des Donn√©es 2025")
        
        # Export du dataset complet
        csv_data = df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger toutes les donn√©es (CSV)",
            data=csv_data,
            file_name=f"analyse_2025_complet_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
        
        # Export par stage si disponible
        if 'Stage' in df.columns:
            stage_summary = df['Stage'].value_counts().reset_index()
            stage_summary.columns = ['Stage', 'Nombre']
            stage_csv = stage_summary.to_csv(index=False).encode('utf-8')
            
            st.download_button(
                label="üìä T√©l√©charger r√©sum√© par Stage (CSV)",
                data=stage_csv,
                file_name=f"stages_2025_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
    
    def render_footer(self):
        """Affichage du footer"""
        if get_config("ui.footer.enabled", False) if CONFIG_LOADED else False:
            app_name = get_config("app.name", "Dashboard Commercial") if CONFIG_LOADED else "Dashboard Commercial"
            app_version = get_config("app.version", "2.0") if CONFIG_LOADED else "2.0"
            
            st.markdown(f"""
            <div class="footer">
                {app_name} v{app_version} | ¬© 2025 | 
                <a href="mailto:support@votredomaine.com" style="color: white;">Support</a>
            </div>
            """, unsafe_allow_html=True)
    
    def render_sidebar_chatbot(self):
        """Widget chatbot dans la sidebar, toujours accessible"""
        # Initialiser l'historique si n√©cessaire
        if 'sidebar_chat_history' not in st.session_state:
            st.session_state.sidebar_chat_history = []
        
        # CSS pour styler le chatbot dans la sidebar
        st.markdown("""
        <style>
        .sidebar-chatbot {
            background: linear-gradient(135deg, #13c2c3, #0a9b9c);
            border-radius: 10px;
            padding: 15px;
            margin: 10px 0;
            color: white;
        }
        .sidebar-chatbot h4 {
            color: white !important;
            margin-bottom: 10px;
        }
        .chat-history {
            max-height: 200px;
            overflow-y: auto;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 5px;
            padding: 8px;
            margin: 10px 0;
            font-size: 12px;
        }
        .quick-buttons {
            display: flex;
            flex-direction: column;
            gap: 5px;
            margin-top: 10px;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Chatbot dans la sidebar (on est d√©j√† dans le contexte sidebar)
        st.markdown('<div class="sidebar-chatbot">', unsafe_allow_html=True)
        st.markdown("#### ü§ñ Assistant IA")
        st.markdown("*Questions rapides*")
        
        # V√©rifier les donn√©es disponibles de mani√®re simple
        chatbot_data_available = False
        data_sources = []
        
        # V√©rifier les donn√©es principales
        if 'chatbot_data_2025' in st.session_state and st.session_state.chatbot_data_2025 is not None:
            chatbot_data_available = True
            data_sources.append("Analyse 2025")
            
        if 'chatbot_data_epargne' in st.session_state and st.session_state.chatbot_data_epargne is not None:
            chatbot_data_available = True
            data_sources.append("√âpargne")
        
        # V√©rifier data_files
        for key, df in self.data_files.items():
            if df is not None and len(df) > 0:
                chatbot_data_available = True
                data_sources.append(key.replace('df_', '').replace('_', ' ').title())
        
        if not chatbot_data_available:
            st.warning("‚ö†Ô∏è Aucune donn√©e charg√©e. Le chatbot peut r√©pondre de mani√®re limit√©e.")
            
            # Widget de chargement rapide pour le chatbot
            with st.expander("üìÅ Chargement rapide pour IA", expanded=False):
                uploaded_file = st.file_uploader(
                    "Charger un fichier pour am√©liorer les r√©ponses",
                    type=['xlsx', 'xls', 'csv'],
                    key="chatbot_file_upload",
                    help="Chargez votre fichier principal pour que l'IA puisse r√©pondre pr√©cis√©ment"
                )
                if uploaded_file:
                    try:
                        # Sauvegarder temporairement sans rerun imm√©diat
                        st.info("üìä Fichier d√©tect√©. Traitement en cours...")
                        
                        from utils.data_processing import read_excel_robust
                        import io
                        df_chatbot = read_excel_robust(io.BytesIO(uploaded_file.getvalue()))
                        if df_chatbot is not None and not df_chatbot.empty:
                            self.data_files['df_chatbot_temp'] = df_chatbot
                            st.success(f"‚úÖ Fichier charg√© ! {len(df_chatbot)} lignes, {len(df_chatbot.columns)} colonnes")
                            st.info("üí° Vous pouvez maintenant poser vos questions √† l'IA")
                        else:
                            st.error("‚ùå Erreur lors du chargement du fichier")
                    except Exception as e:
                        st.error(f"‚ùå Erreur: {str(e)}")
                        st.error("üí° Essayez de charger le fichier dans la page d'analyse correspondante")
        else:
            st.success(f"‚úÖ Donn√©es disponibles : {', '.join(data_sources)}")
        
        # Configuration LLM
        with st.expander("‚öôÔ∏è Configuration LLM", expanded=False):
            st.markdown("**üß† Mod√®les disponibles :**")
            
            # S√©lection du mod√®le
            selected_model = st.selectbox(
                "Mod√®le IA :",
                options=list(self.llm_assistant.available_models.keys()),
                format_func=lambda x: self.llm_assistant.available_models[x]["name"],
                key="llm_model_selection",
                help="Choisissez le mod√®le d'IA pour des analyses plus pouss√©es"
            )
            
            # Configuration des cl√©s API si n√©cessaire
            if selected_model and self.llm_assistant.available_models[selected_model]["requires_key"]:
                api_key = st.text_input(
                    "Cl√© API :",
                    type="password",
                    key=f"api_key_{selected_model}",
                    help=f"Entrez votre cl√© API pour {self.llm_assistant.available_models[selected_model]['name']}"
                )
                
                # Test de connexion
                if api_key:
                    if st.button(f"üîó Tester {selected_model}", key=f"test_{selected_model}"):
                        try:
                            test_result = self.llm_assistant.test_model_connection(selected_model, api_key)
                            if test_result:
                                st.success("‚úÖ Connexion r√©ussie !")
                                st.session_state[f'llm_configured_{selected_model}'] = True
                                st.session_state[f'llm_key_{selected_model}'] = api_key
                            else:
                                st.error("‚ùå √âchec de la connexion")
                        except Exception as e:
                            st.error(f"‚ùå Erreur : {str(e)}")
                            
            # Configuration pour mod√®le local
            elif selected_model == "local":
                st.info("üí° Mod√®le local Ollama - Assurez-vous qu'Ollama est lanc√© sur localhost:11434")
                if st.button("üîó Tester connexion locale", key="test_local"):
                    try:
                        test_result = self.llm_assistant.test_model_connection("local")
                        if test_result:
                            st.success("‚úÖ Ollama d√©tect√© !")
                            st.session_state['llm_configured_local'] = True
                        else:
                            st.error("‚ùå Ollama non disponible")
                    except Exception as e:
                        st.error(f"‚ùå Erreur : {str(e)}")
            
            # Statut de la configuration
            config_status = False
            for model in self.llm_assistant.available_models.keys():
                if st.session_state.get(f'llm_configured_{model}', False):
                    config_status = True
                    st.success(f"üöÄ {self.llm_assistant.available_models[model]['name']} configur√©")
                    break
            
            if not config_status:
                st.warning("‚ö†Ô∏è Aucun mod√®le LLM configur√© - analyses basiques uniquement")
        
        # Interface de saisie compacte
        with st.form(key="sidebar_chatbot_form", clear_on_submit=True):
            quick_question = st.text_input(
                "Votre question :",
                placeholder="Ex: CA total 2024 ?",
                key="sidebar_chat_input",
                label_visibility="collapsed"
            )
            ask_btn = st.form_submit_button("üîç Analyser", use_container_width=True)
            
            if ask_btn and quick_question.strip():
                with st.spinner("ü§î Analyse..."):
                    response = self.process_ai_question(quick_question)
                    st.session_state.sidebar_chat_history.append({
                        'question': quick_question,
                        'response': response[:100] + "..." if len(response) > 100 else response,  # Version courte
                        'full_response': response,
                        'timestamp': datetime.now().strftime("%H:%M")
                    })
        
        # Derni√®re r√©ponse
        if st.session_state.sidebar_chat_history:
            last_chat = st.session_state.sidebar_chat_history[-1]
            st.success(f"**Q:** {last_chat['question']}")
            st.info(f"**R:** {last_chat['response']}")
            
            # Bouton pour voir la r√©ponse compl√®te
            if len(last_chat['full_response']) > 100:
                if st.button("üìÑ R√©ponse compl√®te", key="full_response"):
                    st.text_area("R√©ponse compl√®te:", last_chat['full_response'], height=150)
        
        # Historique compact
        if len(st.session_state.sidebar_chat_history) > 1:
            with st.expander("üìú Historique (5 derniers)"):
                for chat in reversed(st.session_state.sidebar_chat_history[-5:-1]):
                    st.markdown(f"**[{chat['timestamp']}]** {chat['question']}")
                    st.markdown(f"*{chat['response']}*")
                    st.markdown("---")
        
        # Boutons de questions rapides
        st.markdown("**üí° Questions sugg√©r√©es:**")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üí∞ CA", key="sidebar_ca", use_container_width=True):
                response = self.process_ai_question("Quel est notre CA total pour 2024 ?")
                st.session_state.sidebar_chat_history.append({
                    'question': "CA total 2024",
                    'response': response[:100] + "..." if len(response) > 100 else response,
                    'full_response': response,
                    'timestamp': datetime.now().strftime("%H:%M")
                })
            
            if st.button("üë• Clients", key="sidebar_clients", use_container_width=True):
                response = self.process_ai_question("Combien de nouveaux clients avons-nous acquis cette ann√©e ?")
                st.session_state.sidebar_chat_history.append({
                    'question': "Nouveaux clients 2024",
                    'response': response[:100] + "..." if len(response) > 100 else response,
                    'full_response': response,
                    'timestamp': datetime.now().strftime("%H:%M")
                })
        
        with col2:
            if st.button("üèÜ Top", key="sidebar_top", use_container_width=True):
                response = self.process_ai_question("Qui est le meilleur conseiller en termes de CA ?")
                st.session_state.sidebar_chat_history.append({
                    'question': "Top conseiller CA",
                    'response': response[:100] + "..." if len(response) > 100 else response,
                    'full_response': response,
                    'timestamp': datetime.now().strftime("%H:%M")
                })
            
            if st.button("üìä Produits", key="sidebar_products", use_container_width=True):
                response = self.process_ai_question("Quel est notre top 3 des produits ?")
                st.session_state.sidebar_chat_history.append({
                    'question': "Top 3 produits",
                    'response': response[:100] + "..." if len(response) > 100 else response,
                    'full_response': response,
                    'timestamp': datetime.now().strftime("%H:%M")
                })
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Lien vers le chatbot complet
        st.markdown("---")
        st.markdown("üí¨ *Pour des conversations approfondies, utilisez l'onglet **ü§ñ Chatbot IA***")
    
    def run(self):
        """Point d'entr√©e principal de l'application"""
        try:
            self.render_header()
            self.render_sidebar()
            self.render_tabs()
            # self.render_footer()  # Optionnel
            
            self.logger.info("Application rendue avec succ√®s")
            
        except Exception as e:
            self.logger.error(f"Erreur lors du rendu de l'application: {e}")
            st.error("‚ùå **Une erreur est survenue - Application red√©marr√©e**")
            
            # Information pour l'utilisateur
            st.info("üí° **Solutions :**")
            st.markdown("‚Ä¢ Actualisez la page (F5)")
            st.markdown("‚Ä¢ Rechargez vos fichiers si n√©cessaire")
            st.markdown("‚Ä¢ Contactez le support si le probl√®me persiste")
            
            # Bouton pour rafra√Æchir
            if st.button("üîÑ Rafra√Æchir l'application"):
                st.rerun()
            
            if get_config("server.debug", False) if CONFIG_LOADED else False:
                with st.expander("üîß D√©tails techniques (debug)", expanded=False):
                    st.exception(e)


def health_check():
    """Endpoint de sant√© pour Docker health check"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": os.getenv("VERSION", "1.0.0"),
        "service": "dashboard-souscriptions"
    }

# Vous pouvez aussi ajouter une page de sant√© visible
if st.sidebar.button("üîç Health Check"):
    st.json(health_check())
    

def main():
    """Fonction principale"""
    try:
        app = DashboardApp()
        app.run()
    except Exception as e:
        logging.error(f"Erreur critique lors du d√©marrage de l'application: {e}")
        st.error("‚ùå Erreur critique lors du d√©marrage de l'application")
        if st.button("üîÑ Recharger l'application"):
            st.rerun()


if __name__ == "__main__":
    render_crypto_test_section()
    main()
